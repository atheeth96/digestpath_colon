{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm \n",
    "\n",
    "import os, shutil\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import skimage\n",
    "from skimage.io import imread,imsave\n",
    "from skimage import morphology\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage import img_as_uint\n",
    "\n",
    "\n",
    "from digest_patchExtractor import DualPatchExtractor\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from models_pytorch import DualEncoding_U_Net,init_weights\n",
    "from DigestPath_Dataset import DataSet,ToTensor,Scale,Color\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "# from preprocess import fuse_roi,generate_train_mask\n",
    "# from prediction import whole_img_pred,post_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map1_dir_train='/home/vahadaneabhi01/datalab/training-assets/R_medical/atheeth/digest_new/Colonoscopy_tissue_segment_dataset/map_1_train/'\n",
    "map2_dir_train='/home/vahadaneabhi01/datalab/training-assets/R_medical/atheeth/digest_new/Colonoscopy_tissue_segment_dataset/map_2_train/'\n",
    "mask_dir_train='/home/vahadaneabhi01/datalab/training-assets/R_medical/atheeth/digest_new/Colonoscopy_tissue_segment_dataset/mask_train/'\n",
    "map1_patch_dir_train='/home/vahadaneabhi01/datalab/training-assets/R_medical/atheeth/digest_new/Colonoscopy_tissue_segment_dataset/map_1_patches_train/'\n",
    "map2_patch_dir_train='/home/vahadaneabhi01/datalab/training-assets/R_medical/atheeth/digest_new/Colonoscopy_tissue_segment_dataset/map_2_patches_train/'\n",
    "mask_patch_dir_train='/home/vahadaneabhi01/datalab/training-assets/R_medical/atheeth/digest_new/Colonoscopy_tissue_segment_dataset/mask_patches_train/'\n",
    "\n",
    "map1_dir_test='/home/vahadaneabhi01/datalab/training-assets/R_medical/atheeth/digest_new/Colonoscopy_tissue_segment_dataset/map_1_test/'\n",
    "map2_dir_test='/home/vahadaneabhi01/datalab/training-assets/R_medical/atheeth/digest_new/Colonoscopy_tissue_segment_dataset/map_2_test/'\n",
    "mask_dir_test='/home/vahadaneabhi01/datalab/training-assets/R_medical/atheeth/digest_new/Colonoscopy_tissue_segment_dataset/mask_test/'\n",
    "map1_patch_dir_test='/home/vahadaneabhi01/datalab/training-assets/R_medical/atheeth/digest_new/Colonoscopy_tissue_segment_dataset/map_1_patches_test/'\n",
    "map2_patch_dir_test='/home/vahadaneabhi01/datalab/training-assets/R_medical/atheeth/digest_new/Colonoscopy_tissue_segment_dataset/map_2_patches_test/'\n",
    "mask_patch_dir_test='/home/vahadaneabhi01/datalab/training-assets/R_medical/atheeth/digest_new/Colonoscopy_tissue_segment_dataset/mask_patches_test/'\n",
    "\n",
    "dir_list=[map1_dir_train,map2_dir_train,mask_dir_train,map1_patch_dir_train,\\\n",
    "          map2_patch_dir_train,mask_patch_dir_train,map1_dir_test,map2_dir_test,\\\n",
    "          mask_dir_test,map1_patch_dir_test,map2_patch_dir_test,mask_patch_dir_test]\n",
    "for directory in dir_list:\n",
    "    if not os.path.exists(directory):\n",
    "        os.system(\"mkdir {}\".format(directory))\n",
    "        print('made directory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "map_1_dir='Colonoscopy_tissue_segment_dataset/map_1'\n",
    "map_2_dir='Colonoscopy_tissue_segment_dataset/map_2'\n",
    "mask_dir='Colonoscopy_tissue_segment_dataset/tissue-train-pos-v1_mask'\n",
    "\n",
    "all_img_list=os.listdir(map_1_dir)\n",
    "train_list=random.sample(all_img_list, 200)\n",
    "test_list=list(set(all_img_list)-set(train_list))\n",
    "# for train_img in tqdm(train_list):\n",
    "#     mask_img_name=train_img.split('.')[0]+'_mask.jpg'\n",
    "#     shutil.copy(os.path.join(map_1_dir,train_img),os.path.join(map1_dir_train,train_img))\n",
    "#     shutil.copy(os.path.join(map_2_dir,train_img),os.path.join(map2_dir_train,train_img))\n",
    "#     shutil.copy(os.path.join(mask_dir,mask_img_name),os.path.join(mask_dir_train,mask_img_name))\n",
    "    \n",
    "# for test_img in tqdm(test_list):\n",
    "#     test_mask_img_name=test_img.split('.')[0]+'_mask.jpg'\n",
    "#     shutil.copy(os.path.join(map_1_dir,test_img),os.path.join(map1_dir_test,test_img))\n",
    "#     shutil.copy(os.path.join(map_2_dir,test_img),os.path.join(map2_dir_test,test_img))\n",
    "#     shutil.copy(os.path.join(mask_dir,test_mask_img_name),os.path.join(mask_dir_test,test_mask_img_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train_extractor=DualPatchExtractor(map1_dir_train,map2_dir_train,mask_dir_train,map1_patch_dir_train,map2_patch_dir_train\\\n",
    "#                                ,mask_patch_dir_train,overlap=False,progress_bar=True)\n",
    "\n",
    "# train_extractor.extract_patches()\n",
    "\n",
    "# test_extractor=DualPatchExtractor(map1_dir_test,map2_dir_test,mask_dir_test,map1_patch_dir_test,map2_patch_dir_test\\\n",
    "#                                ,mask_patch_dir_test,overlap=False,progress_bar=True)\n",
    "\n",
    "# test_extractor.extract_patches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train=4\n",
    "batch_size_test=4\n",
    "transform=torchvision.transforms.Compose([Scale(),ToTensor()])    \n",
    "\n",
    "\n",
    "\n",
    "train_dataset=DataSet(map1_patch_dir_train,map2_patch_dir_train,mask_patch_dir_train,transform=transform)\n",
    "train_loader=DataLoader(train_dataset,batch_size=batch_size_train,num_workers=0,shuffle=True)\n",
    "print(train_dataset.__len__(),\" Train samples\")\n",
    "\n",
    "test_dataset=DataSet(map1_patch_dir_test,map2_patch_dir_test,mask_patch_dir_test,transform=transform)\n",
    "test_loader=DataLoader(test_dataset,batch_size=batch_size_test,num_workers=0,shuffle=False)\n",
    "print(test_dataset.__len__(),\" Test samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def dice_metric(y_pred,y_true):\n",
    "    smooth = 1\n",
    "    num = y_true.size(0)\n",
    "    m1 = y_pred.view(num, -1)\n",
    "    m2 = y_true.view(num, -1)\n",
    "    \n",
    "        \n",
    "    intersection = (m1* m2)\n",
    "\n",
    "    score = 2. * (intersection.sum(1) + smooth) / (m1.sum(1) + m2.sum(1) + smooth)\n",
    "    score = score.sum() / num\n",
    "        \n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_loader(loader,index):\n",
    "    for i,sample in enumerate(loader):\n",
    "        #print(sample['image'].shape)\n",
    "        if i==1:\n",
    "            map1=(sample['map1'][index]).numpy()\n",
    "            \n",
    "            \n",
    "            #image=np.zeros(image_i.shape,dtype=np.uint8)\n",
    "            #image[np.where(image_i!=0)]=255\n",
    "\n",
    "            map2=(sample['map2'][index]).numpy()\n",
    "            \n",
    "        \n",
    "            mask=(sample['mask'][index]).numpy()\n",
    "        \n",
    "           \n",
    "    \n",
    "            map1=map1.transpose(1,2,0)\n",
    "            map2=map2.transpose(1,2,0)\n",
    "            mask=np.squeeze(mask.transpose(1,2,0),axis=2)\n",
    "            print(map1.shape,np.amax(map1))\n",
    "        \n",
    "            fig=plt.figure()\n",
    "            plt.imshow(map1)\n",
    "            fig2=plt.figure()\n",
    "            plt.imshow(map2)\n",
    "            fig3=plt.figure()\n",
    "            plt.imshow(mask)\n",
    "            break\n",
    "visualize_loader(test_loader,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=DualEncoding_U_Net()\n",
    "model_start_date=datetime.datetime.now().strftime(\"%Y_%m_%d\")\n",
    "BEST_MODEL_PATH=os.path.join(os.getcwd(),'model_{}'.format(model_start_date))\n",
    "if not os.path.exists(BEST_MODEL_PATH):\n",
    "    os.mkdir(BEST_MODEL_PATH)\n",
    "    print('model_{} dir has been made'.format(model_start_date))\n",
    "print(\"Model's state_dict:\")\n",
    "writer = SummaryWriter('model_{}/experiment_{}'.format(model_start_date,1))\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "optimizer_selected='adam'\n",
    "batchsize=4\n",
    "no_steps=train_dataset.__len__()//batchsize\n",
    "restart_epochs=8\n",
    "num_epochs=10\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#criterion = SoftDiceLoss()#\n",
    "criterion=nn.BCELoss()\n",
    "\n",
    "history={'train_loss':[],'test_loss':[],'train_dice':[],'test_dice':[]}\n",
    "model = model.to(device)\n",
    "if optimizer_selected=='adam':\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=1e-03, betas=(0.9, 0.98))#,weight_decay=0.02)\n",
    "else:\n",
    "    optimizer = torch.optim.SGD(model.parameters(),lr=1e-03, momentum=0.8,nesterov=True)\n",
    "\n",
    "scheduler=torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, restart_epochs*no_steps,\\\n",
    "                                                     eta_min=1e-012, last_epoch=-1)\n",
    "\n",
    "\n",
    "best_val=0\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    print(\"Learning Rate : {}\".format(optimizer.state_dict()['param_groups'][-1]['lr']))\n",
    "    # loop over the dataset multiple times\n",
    "    \n",
    "    run_avg_train_loss=0\n",
    "    run_avg_train_dice=0\n",
    "    \n",
    "   \n",
    "    \n",
    "    run_avg_test_loss=0\n",
    "    run_avg_test_dice=0\n",
    "    \n",
    "    for mode in ['train','eval']:\n",
    "     \n",
    "        if mode == 'train':\n",
    "            \n",
    "            model.train()\n",
    "            loop=tqdm(train_loader)\n",
    "            \n",
    "            for i, sample_batched in (enumerate(loop)):\n",
    "                loop.set_description('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "                \n",
    "                #Clear Gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # get the inputs; data is a list of [dapi, nuclei, boundary]\n",
    "                map1_batch, map2_batch,mask_batch = sample_batched['map1'],\\\n",
    "                sample_batched['map2'],sample_batched['mask']\n",
    "                \n",
    "                map1_batch, map2_batch,mask_batch = map1_batch.to(device, dtype = torch.float)\\\n",
    "                ,map2_batch.to(device, dtype = torch.float),mask_batch.to(device,dtype=torch.float)\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = torch.sigmoid(model(map1_batch,map2_batch))\n",
    "                \n",
    "                loss = criterion(outputs, mask_batch)\n",
    "                dice_score=dice_metric(outputs,mask_batch)\n",
    "                run_avg_train_loss=(run_avg_train_loss*(0.9))+loss.detach().item()*0.1\n",
    "                run_avg_train_dice=(run_avg_train_dice*(0.9))+dice_score.detach().item()*0.1\n",
    "               \n",
    "                if i%100==99:\n",
    "                    \n",
    "                \n",
    "                    \n",
    "                    img_tensor=torch.cat((outputs.detach().cpu(),mask_batch.detach().cpu()),axis=0)\n",
    "                    \n",
    "                    \n",
    "            \n",
    "                    img_grid2 = torchvision.utils.make_grid(img_tensor*255,nrow=batch_size_train,padding=100)\n",
    "                    torchvision.utils.save_image(img_grid2,os.path.join(BEST_MODEL_PATH,\\\n",
    "                                                                        'train_iter_{}.png'\\\n",
    "                                                                        .format(epoch*len(train_loader)+i+1)))\n",
    "                    writer.add_image('TRAIN_ITER_{}'.format(epoch * len(train_loader) + i+1), img_grid2)\n",
    "                    \n",
    "                    \n",
    "                    writer.add_scalar('Training dice score nuclei',\n",
    "                            run_avg_train_dice,\n",
    "                            epoch * len(train_loader) + i+1)\n",
    "                \n",
    "                    writer.add_scalar('Training Loss',\n",
    "                            run_avg_train_loss,\n",
    "                            epoch * len(train_loader) + i+1)\n",
    "                    \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                scheduler.step()\n",
    "                \n",
    "                \n",
    "                loop.set_postfix(loss=run_avg_train_loss,dice_score=run_avg_train_dice)\n",
    "               \n",
    "            history['train_loss'].append(run_avg_train_loss)\n",
    "            history['train_dice'].append(run_avg_train_dice)\n",
    "                \n",
    "                 \n",
    "                    \n",
    "        elif mode =='eval':\n",
    "            #Clear Gradients\n",
    "            optimizer.zero_grad()\n",
    "            samples_test=len(test_loader)\n",
    "            model.eval()\n",
    "            val_loss=0\n",
    "            test_agg=0\n",
    "            for j, test_sample in enumerate(test_loader):\n",
    "\n",
    "                test_map1_batch, test_map2_mask_batch,test_mask_batch = test_sample['map1']\\\n",
    "                , test_sample['map2'],test_sample['mask']\n",
    "                \n",
    "                test_map1_batch, test_map2_mask_batch,test_mask_batch = test_map1_batch.to(device, dtype = torch.float),\\\n",
    "                test_map2_mask_batch.to(device, dtype = torch.float),test_mask_batch.to(device, dtype = torch.float)\n",
    "                test_outputs = torch.sigmoid(model(test_map1_batch,test_map2_batch))\n",
    "                \n",
    "                test_loss = criterion(test_outputs, test_mask_batch)\n",
    "                #final_test_loss+=test_loss.detach().item()\n",
    "                test_dice=dice_metric(test_outputs,test_mask_batch)\n",
    "                #final_test_dice+=test_dice\n",
    "                run_avg_test_loss=(run_avg_test_loss*(0.9))+test_loss.detach().item()*0.1\n",
    "                run_avg_test_dice=(run_avg_test_dice*(0.9))+test_dice.detach().item()*0.1\n",
    "               \n",
    "                if j%100==99:\n",
    "                    \n",
    "                    img_tensor_test=torch.cat((test_outputs.detach().cpu(),test_mask_batch.detach().cpu()),axis=0)\n",
    "                    \n",
    "                    \n",
    "                    img_grid = torchvision.utils.make_grid(img_tensor_test*255,nrow=batch_size_test,padding=10)\n",
    "                    torchvision.utils.save_image(img_grid,os.path.join(BEST_MODEL_PATH,\\\n",
    "                                                                        'test_iter_{}.png'\\\n",
    "                                                                        .format(epoch*len(test_loader)+j+1)))\n",
    "                    writer.add_image('TEST_ITER_{}'.format(epoch * len(test_loader) + j+1), img_grid)\n",
    "                    writer.add_scalar('Testing dice score ',\\\n",
    "                                      run_avg_test_dice,epoch * len(test_loader) + j+1)\n",
    "                    \n",
    "                    writer.add_scalar('Testing Loss',\\\n",
    "                                      run_avg_test_loss,epoch * len(test_loader) + j+1)\n",
    "                \n",
    "            print(\"test_loss: {}\\ntest_dice :{}\"\\\n",
    "                  .format(run_avg_test_loss,run_avg_test_dice))\n",
    "            history['test_loss'].append(run_avg_test_loss)\n",
    "            history['test_dice'].append(run_avg_test_dice)\n",
    "            if run_avg_test_dice>best_val:\n",
    "                best_val=run_avg_test_dice\n",
    "                torch.save(model.state_dict(), BEST_MODEL_PATH+'/model_optim.pth')\n",
    "                print(\"saved model with test dice score: {}\".format(best_val))\n",
    "\n",
    "        \n",
    "#             print(\"val_loss {}\".format(val_loss/samples_test))\n",
    "torch.save(model.state_dict(), BEST_MODEL_PATH+'/model_final.pth')\n",
    "print('Finished Training')\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
