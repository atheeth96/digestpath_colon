{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (DatabaseError('database disk image is malformed',)).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm \n",
    "\n",
    "import os, shutil\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import skimage\n",
    "from skimage.io import imread,imsave\n",
    "from skimage import morphology\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage import img_as_uint\n",
    "\n",
    "\n",
    "from digest_patchExtractor import DualPatchExtractor\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from models_pytorch import DualEncoding_U_Net,init_weights\n",
    "from DigestPath_Dataset import DataSet,ToTensor,Scale,Color\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "# from preprocess import fuse_roi,generate_train_mask\n",
    "# from prediction import whole_img_pred,post_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colon_post.ipynb\t\tmask_cn_overlap_val\r\n",
      "colon_unet_keras.ipynb\t\tmasked_img\r\n",
      "colon_unet_resized_keras.ipynb\tmodel_2019_08_26\r\n",
      "Digest_DualEncoding.ipynb\tmodel_2019_08_29\r\n",
      "digest_patchExtractor.py\tmodel_2019_08_30\r\n",
      "DigestPath_Dataset.py\t\tmodel_non_cn_unet2019_10_04\r\n",
      "entire_image_2019_10_14\t\tmodel_non_overlap_unet2019_10_10\r\n",
      "input_cn_overlap_test\t\tmodels_pytorch.py\r\n",
      "input_cn_overlap_train\t\tmodel_vanilla_unet2019_10_01\r\n",
      "input_cn_overlap_val\t\tnorm_images.ipynb\r\n",
      "__MACOSX\t\t\tpatch_extractor.ipynb\r\n",
      "map_1\t\t\t\tpatch_extractor.py\r\n",
      "map_1_gray\t\t\tpredictions.csv\r\n",
      "map_1_gray_matlab\t\tpredict_unet_colon_keras.ipynb\r\n",
      "map_1_matlab\t\t\t__pycache__\r\n",
      "map_2\t\t\t\trequirements_datalab.txt\r\n",
      "map_2_gray\t\t\trequirements.txt\r\n",
      "map_2_gray_matlab\t\ttissue-train-neg_norm\r\n",
      "map_2_matlab\t\t\ttissue-train-pos-v1_color_normalized\r\n",
      "mask_cn_overlap_test\t\ttissue-train-pos-v1_mask\r\n",
      "mask_cn_overlap_train\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6be039c2b0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASwAAAD7CAYAAADQMalWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAKzElEQVR4nO3dT4ic9RnA8e9TE3aRxCxBg+YScqgFi8GYoRtoCAERaQkoqIeAFMS4VLAX8ZCj5FzBWyWB0pMnpSWIEFGzyBYSkk0ighAMKf5hvSyW1FOI9elh3k03ySb77o6zM8/s9wML8/5myDyzbL75ve/MamQmklTBLwY9gCS1ZbAklWGwJJVhsCSVYbAklWGwJJXR12BF1/GIOB8RR/v5XJJGX793WHuBcaADTEXE9j4/n6QR1u9g7QFOAbuAGWB3n59P0gjb0Oc/fwvwNbANmG6Ob4iIKWAK4B7u2XMv9/V5HEnD7gf+PZ+ZDyx1X7+DdRUYA76gu9v61+I7M/MYcAzgvtiak/FEn8eRNOw+yne/utN9/T4lnAUmM/MysB+40OfnkzTC+h2s08BERJwBzmbmXJ+fT9II6+spYXb/UxCH+/kcktYPPzgqqQyDJakMgyWpDIMlqQyDJakMgyWpDIMlqQyDJakMgyWpDIMlqQyDJakMgyWpDIMlqQyDJakMgyWpDIMlqQyDJakMgyWpDIMlqQyDJakMgyWpDIMlqQyDJakMgyWpDIMlqQyDJakMgyWpDIMlqQyDJakMgyWpDIMlqQyDJakMgyWpDIMlqQyDJakMgyWpDIMlqYxlgxURhyJiPiLGo+t4RJyPiKPN/a3WJKlXG1o85gfgUnN7LzAOdIC5iHgb2NFmLTPnfu7hJa0vy+6wMvN94HpzuAc4BewCZoDdK1iTpJ6s9BrWFmAe2AZMN8dt1ySpJysN1lVgDLgCbG6O267dJiKmIuJcRJy7zrVVvQBJ68dKgzULTGbmZWA/cGEFa7fJzGOZ2cnMzkbGVvsaJK0TKw3WaWAiIs4AZ5sL6W3XJKknbd4lJDMPLDo8fMt92WZNknrlB0cllWGwJJVhsCSVYbAklWGwJJVhsCSVYbAklWGwJJVhsCSVYbAklWGwJJVhsCSVYbAklWGwJJVhsCSVYbAklWGwJJVhsCSVYbAklWGwJJVhsCSVYbAklWGwJJVhsCSVYbAklWGwJJVhsCSVYbAklWGwJJVhsCSVYbAklWGwJJVhsCSVYbAklWGwJJVhsCSVYbAklWGwJJWxbLAiYiwi3omImYg40Rwfj4jzEXG0eUy0WZOkXrTZYT0PXMzMfcCXwBFgHOgAUxGxHdjbck2SVm1Di8d8Bkw3t38EEjgF7AJmgN3AzpZrcz/f6JLWm2WDlZmfA0TEM8AW4D/APLCNbsi2NF9ft1i7SURMAVMA49zb2yuRNPJaXXSPiBeAfcArwFVgDLgCbG6O267dJDOPZWYnMzsbGev5xUgabW0uuu8Ans3M1zMzgVlgMjMvA/uBCytYk6RVa7PDegl4tHmXcAZ4GJiIiDPA2cycA063XJOkVYvupmnw7outORlPDHoMSQP2Ub47m5mdpe7zg6OSyjBYksowWJLKMFiSyjBYksowWJLKMFiSyjBYksowWJLKMFiSyjBYksowWJLKMFiSyjBYksowWJLKMFiSyjBYWpGTcxc5OXdx0GNonTJYam1xqCpEy7iOHoOl1p7a/tigR2jNUI0mgyWpjDb/52fphkq7rAUn5y6WnFu3c4elkWesRofB0khaiNStsVq4EO81rpoMlkbWUrG627GGn8HSurBUnDxVrMeL7hp5bXZSix9jyIaXOyyte54q1uEOSyPvqe2P3YiQu6faDJaGTj9OzwzVaPCUUEPHuOhO3GFpKK1ltDxlrMNgSRiqKjwllFSGwZJUhsGSVIbBklSGwZJUxrLBiohNEfFBRMxExMcR8VBEHI+I8xFxtHlMtFmTpF602WFNAEcycx/wCTAFjAMdYCoitgN7W65J0qotG6zM/Ba4FhGzwJPA98ApYBcwA+wG9rRck6RVa3UNKzMvZeZCgLYC88A2YBrY0ny1WbtJRExFxLmIOHedaz2+FEmjrs01rJ0R8UBzeAJ4AxgDrgCbgavNV5u1m2TmsczsZGZnI2M9vxhJo63NDmsSeLW5/TjdYE1m5mVgP3ABmG25Jkmr1iZY7wE7I+JT4CDwFjAREWeAs5k5B5xuuSZJq7bsLz9n5nXgD7csH77lMdlmTZJ64QdHJZVhsCSVYbAklWGwJJVhsCSVYbAklWGwJJVhsCSVYbAklWGwJJVhsCSVYbAklWGwJJVhsCSVYbAklWGwJJVhsCSVYbAklWGwJJVhsCSVYbAklWGwJJVhsCSVYbAklWGwJJVhsCSVYbAklWGwJJVhsCSVYbAklWGwJJVhsCSVYbAklWGwJJVhsCSVYbAklWGwJJXRKlgR8VxEfBddxyPifEQcbe5rtSZJvdqw3AMi4kHgEPANsBcYBzrAXES8Dexos5aZc/15CZLWizY7rDeB14CfgD3AKWAXMAPsXsGaJPXkrsGKiJeBDzPzq2ZpCzAPbAOmm+O2a0v9+VMRcS4izl3nWo8vRdKoW26H9TTwYkRMA4/Q3WmNAVeAzcDV5qvN2m0y81hmdjKzs5Gxnl+MpNF212Bl5sHMPJCZB4AvgIPAZGZeBvYDF4DZlmuS1tDJuYuDHuFnt9KPNZwGJiLiDHC2uZDedk3SGlmI1ahFa9l3CRdk5t7m5uFb1rPNmiT1qnWwJNXx1PbHBj1CX/hJd0llGCxJZRgsSWUYLEllGCxJZRgsSWUYLEllGCxJZRgsSWUYLEllGCxJZRgsSWUYLEllGCxJZRgsSWUYLEllGCxJZRgsSWUYLEllGCxJZRgsSWUYLEllGCxJZRgsSWUYLEllGCxJZRgsSWUYLEllGCxJZRgsSWUYLEllRGYOegYAIuIH4NKg51ih+4H5QQ+xChXndua1M+i5d2TmA0vdsWGtJ7mLS5nZGfQQKxER56rNDDXndua1M8xze0ooqQyDJamMYQrWsUEPsAoVZ4aaczvz2hnauYfmorskLWeYdliSdFcGS1IZAw9WdB2PiPMRcXTQ8ywWEYciYj4ixpeas+3aGs47FhHvRMRMRJxojod65ub5N0XEB83cH0fEQ0Xmfi4ivqvws9E8/68j4uvm+zwTEb+sMPdiAw8WsBcYBzrAVERsH/A8iy3+MOtSc7ZdWyvPAxczcx/wJXCkwMwAE8CRZu5PgKlhnzsiHgQOAd+sYLZBf583AX/NzH3N9/r+InPfMAzB2gOcAnYBM8DuwY7zf5n5PnC9OVxqzrZra+Uz4J3m9o9AFpiZzPwWuBYRs8CTwPcF5n4TeA34aQWzDfpnfRPwu4j4Z0T8A/hNkblvGIZgbaH7awDbgOnmeBgtNWfbtTWRmZ9n5rcR8UzzvP8d9pkXZOalzFz4i7G15YwDmTsiXgY+zMyvmqWh/9lozAN/y8zf0v3HbaLljIOe+4ZhCNZVYAy4AmxujofRUnO2XVszEfECsA94pdDMOyNi4XfHTgBvDPncTwMvRsQ08AjdndYwzwtAZn6WmX9pDs8Af6ow92LDEKxZYDIzLwP7gQsDnudOlpqz7dqaiIgdwLOZ+Xp2P2A39DM3JoFXm9uP0w3W0M6dmQcz80BmHgC+AA4O87wLovsm0h+bw710T2uHfu7FhiFYp4GJiDgDnM3MuUEPdAdLzdl2ba28BDy68C4Q8HCBmQHeA3ZGxKd0//K/VWTuBRV+NgD+Dvw+Ik4DvwL+XGTuG/yku6QyhmGHJUmtGCxJZRgsSWUYLEllGCxJZRgsSWUYLEll/A/cLDvrl/1bMAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "a=imread('tissue-train-pos-v1_mask/18-01080B_2019-05-07 21_33_52-lv1-15262-19621-5715-4803_mask.jpg')\n",
    "a2=imread('tissue-train-pos-v1_mask/18-01080B_2019-05-07 21_33_52-lv1-15262-19621-5715-4803_mask.jpg')\n",
    "thresh = threshold_otsu(a)\n",
    "a2 = a > thresh\n",
    "a=a>0\n",
    "a=a.astype(np.uint8)*255\n",
    "print(np.amax(a))\n",
    "plt.imshow(a)\n",
    "fig=plt.figure()\n",
    "plt.imshow(a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "made directory\n",
      "made directory\n",
      "made directory\n",
      "made directory\n",
      "made directory\n",
      "made directory\n",
      "made directory\n",
      "made directory\n",
      "made directory\n",
      "made directory\n",
      "made directory\n",
      "made directory\n"
     ]
    }
   ],
   "source": [
    "map1_dir_train='/home/vahadaneabhi01/datalab/training-assets/R_medical/atheeth/digest_new/colon_repo/digest_path/map_1_train/'\n",
    "map2_dir_train='/home/vahadaneabhi01/datalab/training-assets/R_medical/atheeth/digest_new/colon_repo/digest_path/map_2_train/'\n",
    "mask_dir_train='/home/vahadaneabhi01/datalab/training-assets/R_medical/atheeth/digest_new/colon_repo/digest_path/mask_train/'\n",
    "map1_patch_dir_train='/home/vahadaneabhi01/datalab/training-assets/R_medical/atheeth/digest_new/colon_repo/digest_path/map_1_patches_train/'\n",
    "map2_patch_dir_train='/home/vahadaneabhi01/datalab/training-assets/R_medical/atheeth/digest_new/colon_repo/digest_path/map_2_patches_train/'\n",
    "mask_patch_dir_train='/home/vahadaneabhi01/datalab/training-assets/R_medical/atheeth/digest_new/colon_repo/digest_path/mask_patches_train/'\n",
    "\n",
    "map1_dir_test='/home/vahadaneabhi01/datalab/training-assets/R_medical/atheeth/digest_new/colon_repo/digest_path/map_1_test/'\n",
    "map2_dir_test='/home/vahadaneabhi01/datalab/training-assets/R_medical/atheeth/digest_new/colon_repo/digest_path/map_2_test/'\n",
    "mask_dir_test='/home/vahadaneabhi01/datalab/training-assets/R_medical/atheeth/digest_new/colon_repo/digest_path/mask_test/'\n",
    "map1_patch_dir_test='/home/vahadaneabhi01/datalab/training-assets/R_medical/atheeth/digest_new/colon_repo/digest_path/map_1_patches_test/'\n",
    "map2_patch_dir_test='/home/vahadaneabhi01/datalab/training-assets/R_medical/atheeth/digest_new/colon_repo/digest_path/map_2_patches_test/'\n",
    "mask_patch_dir_test='/home/vahadaneabhi01/datalab/training-assets/R_medical/atheeth/digest_new/colon_repo/digest_path/mask_patches_test/'\n",
    "\n",
    "dir_list=[map1_dir_train,map2_dir_train,mask_dir_train,map1_patch_dir_train,\\\n",
    "          map2_patch_dir_train,mask_patch_dir_train,map1_dir_test,map2_dir_test,\\\n",
    "          mask_dir_test,map1_patch_dir_test,map2_patch_dir_test,mask_patch_dir_test]\n",
    "for directory in dir_list:\n",
    "    if not os.path.exists(directory):\n",
    "        os.system(\"mkdir {}\".format(directory))\n",
    "        print('made directory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cdec169a4c14bf081a2046c95b692fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=150), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "154544106b6c457d8a152642f4052a34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=42), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "map_1_dir='map_1_gray_matlab'\n",
    "map_2_dir='map_2_gray_matlab'\n",
    "mask_dir='tissue-train-pos-v1_mask'\n",
    "\n",
    "all_img_list=os.listdir(map_1_dir)\n",
    "\n",
    "train_list=random.sample(all_img_list, 150)\n",
    "test_list=list(set(all_img_list)-set(train_list))\n",
    "for train_img in tqdm(train_list):\n",
    "    mask_img_name=train_img.split('.')[0]+'_mask.jpg'\n",
    "    shutil.copy(os.path.join(map_1_dir,train_img),os.path.join(map1_dir_train,train_img))\n",
    "    shutil.copy(os.path.join(map_2_dir,train_img),os.path.join(map2_dir_train,train_img))\n",
    "    shutil.copy(os.path.join(mask_dir,mask_img_name),os.path.join(mask_dir_train,mask_img_name))\n",
    "    \n",
    "for test_img in tqdm(test_list):\n",
    "    test_mask_img_name=test_img.split('.')[0]+'_mask.jpg'\n",
    "    shutil.copy(os.path.join(map_1_dir,test_img),os.path.join(map1_dir_test,test_img))\n",
    "    shutil.copy(os.path.join(map_2_dir,test_img),os.path.join(map2_dir_test,test_img))\n",
    "    shutil.copy(os.path.join(mask_dir,test_mask_img_name),os.path.join(mask_dir_test,test_mask_img_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import scipy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#import cv2\n",
    "import imutils\n",
    "import re\n",
    "\n",
    "\n",
    "import zipfile\n",
    "\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.feature_extraction import image\n",
    "\n",
    "\n",
    "import skimage\n",
    "from skimage.util import pad\n",
    "from skimage import draw\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.transform import resize\n",
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm_notebook as tqdm \n",
    "\n",
    "class DualPatchExtractor():\n",
    "    def __init__(self,map1_dir,map2_dir,mask_dir,map1_patch_dir,map2_patch_dir\\\n",
    "    ,mask_patch_dir,gray=True,overlap=False,progress_bar=True):\n",
    "    \n",
    "        \n",
    "        self.map1_dir=map1_dir\n",
    "        self.map2_dir=map2_dir\n",
    "        self.mask_dir=mask_dir\n",
    "        \n",
    "        self.map1_patch_dir=map1_patch_dir\n",
    "        self.map2_patch_dir=map2_patch_dir\n",
    "        self.mask_patch_dir=mask_patch_dir\n",
    "        \n",
    "        self.gray=gray\n",
    "        self.overlap=overlap\n",
    "        self.progress_bar=progress_bar\n",
    "        \n",
    "\n",
    "    def extract_patches(self):\n",
    "        if self.overlap:\n",
    "            step=256\n",
    "        else:\n",
    "            step=512\n",
    "        NO_PATCHES=0\n",
    "        \n",
    "#       for tag in ['train','test']:\n",
    "        map1_patch_dir=self.map1_patch_dir\n",
    "        map2_patch_dir=self.map2_patch_dir\n",
    "        mask_patch_dir=self.mask_patch_dir\n",
    "\n",
    "        if not os.path.exists(map1_patch_dir):\n",
    "            os.mkdir(map1_patch_dir)\n",
    "            if self.progress_bar:\n",
    "                print(\"Map1 patch directory made\")\n",
    "        if not os.path.exists(map2_patch_dir):\n",
    "            os.mkdir(map2_patch_dir)\n",
    "            if self.progress_bar:\n",
    "                print(\"Map2 patch directory made\")\n",
    "        if not os.path.exists(mask_patch_dir):\n",
    "            os.mkdir(mask_patch_dir)\n",
    "            if self.progress_bar:\n",
    "                print(\"Mask patch directory made\")\n",
    "      \n",
    "        exception_list=[]\n",
    "        \n",
    "       \n",
    "        slides=[x for x in os.listdir(self.map1_dir) if '.jpg' in x\\\n",
    "                and x in os.listdir(self.map2_dir) and x.split('.')[0]+'_mask.jpg' in os.listdir(self.mask_dir)]\n",
    "\n",
    "        if self.progress_bar:\n",
    "            loop=tqdm(slides)\n",
    "        else:\n",
    "            loop=slides\n",
    "        for slide in loop:\n",
    " \n",
    "#             try:\n",
    "\n",
    "            map1_path=os.path.join(self.map1_dir,slide)\n",
    "            map2_path=os.path.join(self.map2_dir,slide)\n",
    "            mask_path=os.path.join(self.mask_dir,slide.split('.')[0]+'_mask.jpg')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            map1_img=imread(map1_path)\n",
    "            map2_img=imread(map2_path)\n",
    "            mask_img=imread(mask_path)\n",
    "            mask_img=mask_img>0\n",
    "            mask_img=mask_img.astype(np.uint8)*255\n",
    "\n",
    "            \n",
    "            r,c=map1_img.shape[:2]\n",
    "\n",
    "            new_r_count=(math.ceil((r-512)/512)+1)\n",
    "            new_c_count=(math.ceil((c-512)/512)+1)\n",
    "\n",
    "\n",
    "            pad_r1=((new_r_count-1)*512-r+512)//2 \n",
    "            pad_r2=((new_r_count-1)*512-r+512)-pad_r1 \n",
    "            pad_c1=((new_c_count-1)*512-c+512)//2 \n",
    "            pad_c2=((new_c_count-1)*512-c+512)-pad_c1 \n",
    "            \n",
    "            if self.gray:\n",
    "                map1_padded=np.pad(map1_img, [(pad_r1,pad_r2),(pad_c1,pad_c2)], 'constant', constant_values=0)\n",
    "                map2_padded=np.pad(map2_img, [(pad_r1,pad_r2),(pad_c1,pad_c2)], 'constant', constant_values=0)\n",
    "                window_shape=(512,512)\n",
    "            else:\n",
    "                map1_padded=np.pad(map1_img, [(pad_r1,pad_r2),(pad_c1,pad_c2),(0,0)], 'constant', constant_values=0)\n",
    "                map2_padded=np.pad(map2_img, [(pad_r1,pad_r2),(pad_c1,pad_c2),(0,0)], 'constant', constant_values=0)#/np.amax(input_image)\n",
    "                window_shape=(512,512,3)\n",
    "            mask_padded=np.pad(mask_img, [(pad_r1,pad_r2),(pad_c1,pad_c2)], 'constant', constant_values=0)\n",
    "\n",
    "            \n",
    "            window_shape_mask=(512,512)\n",
    "\n",
    "            map1_patches=skimage.util.view_as_windows(map1_padded, window_shape, step=step)\n",
    "            map2_patches=skimage.util.view_as_windows(map2_padded, window_shape, step=step)\n",
    "            mask_patches=skimage.util.view_as_windows(mask_padded, window_shape_mask, step=step)\n",
    "            \n",
    "            if self.gray:\n",
    "                map1_patches=map1_patches.reshape((-1,512,512))\n",
    "                map2_patches=map2_patches.reshape((-1,512,512))\n",
    "            else:\n",
    "                map1_patches=map1_patches.reshape((-1,512,512,3))\n",
    "                map2_patches=map2_patches.reshape((-1,512,512,3))\n",
    "\n",
    "            \n",
    "            mask_patches=mask_patches.reshape((-1,512,512))\n",
    "\n",
    "\n",
    "            for i,(map1_patch,map2_patch,mask_patch) in enumerate(zip(map1_patches,map2_patches,mask_patches)):\n",
    "                if len(np.where(mask_patch==255)[0])>=5000:\n",
    "                    NO_PATCHES+=1\n",
    "\n",
    "\n",
    "                    imsave(os.path.join(map1_patch_dir,slide.split('.')[0]+'_{}.jpg'.format(i+1)),map1_patch)\n",
    "                    imsave(os.path.join(map2_patch_dir,slide.split('.')[0]+'_{}.jpg'.format(i+1)),map2_patch)\n",
    "                    imsave(os.path.join(mask_patch_dir,slide.split('.')[0]+'_{}_mask.jpg'.format(i+1)),mask_patch)\n",
    "\n",
    "#             except:\n",
    "#                 exception_list.append(slide.split('.')[0])\n",
    "        if self.progress_bar:\n",
    "            print(\"NUMBER OF PATCHES ARE {}\".format(NO_PATCHES),'\\nException\\n',*exception_list,sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df2b1b121beb4d8ab85051419d6c6e2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=150), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with remapped shapes [original->remapped]: (3,2) and requested shape (2,2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-c6403169749a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                                ,mask_patch_dir_train,overlap=False,progress_bar=True)\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_patches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m test_extractor=DualPatchExtractor(map1_dir_test,map2_dir_test,mask_dir_test,map1_patch_dir_test,map2_patch_dir_test\\\n",
      "\u001b[0;32m<ipython-input-28-60f05c0c5b76>\u001b[0m in \u001b[0;36mextract_patches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mpad_c2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_c_count\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpad_c1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mmap1_padded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap1_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_r1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpad_r2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_c1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpad_c2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'constant'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstant_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0mmap2_padded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap2_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_r1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpad_r2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_c1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpad_c2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'constant'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstant_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#/np.amax(input_image)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mmask_padded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_r1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpad_r2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_c1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpad_c2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'constant'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstant_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mpad\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/lib/arraypad.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(array, pad_width, mode, **kwargs)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m     \u001b[0;31m# Broadcast to shape (array.ndim, 2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m     \u001b[0mpad_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_as_pairs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/lib/arraypad.py\u001b[0m in \u001b[0;36m_as_pairs\u001b[0;34m(x, ndim, as_index)\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;31m# Converting the array with `tolist` seems to improve performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0;31m# when iterating and indexing the result (see usage in `pad`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mbroadcast_to\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/lib/stride_tricks.py\u001b[0m in \u001b[0;36mbroadcast_to\u001b[0;34m(array, shape, subok)\u001b[0m\n\u001b[1;32m    180\u001b[0m            [1, 2, 3]])\n\u001b[1;32m    181\u001b[0m     \"\"\"\n\u001b[0;32m--> 182\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_broadcast_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/lib/stride_tricks.py\u001b[0m in \u001b[0;36m_broadcast_to\u001b[0;34m(array, shape, subok, readonly)\u001b[0m\n\u001b[1;32m    125\u001b[0m     it = np.nditer(\n\u001b[1;32m    126\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'multi_index'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'refs_ok'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'zerosize_ok'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextras\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         op_flags=['readonly'], itershape=shape, order='C')\n\u001b[0m\u001b[1;32m    128\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;31m# never really has writebackifcopy semantics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with remapped shapes [original->remapped]: (3,2) and requested shape (2,2)"
     ]
    }
   ],
   "source": [
    "\n",
    "train_extractor=DualPatchExtractor(map1_dir_train,map2_dir_train,mask_dir_train,map1_patch_dir_train,map2_patch_dir_train\\\n",
    "                               ,mask_patch_dir_train,overlap=False,progress_bar=True)\n",
    "\n",
    "train_extractor.extract_patches()\n",
    "\n",
    "test_extractor=DualPatchExtractor(map1_dir_test,map2_dir_test,mask_dir_test,map1_patch_dir_test,map2_patch_dir_test\\\n",
    "                               ,mask_patch_dir_test,overlap=False,progress_bar=True)\n",
    "\n",
    "test_extractor.extract_patches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train=4\n",
    "batch_size_test=4\n",
    "transform=torchvision.transforms.Compose([Scale(),ToTensor()])    \n",
    "\n",
    "\n",
    "\n",
    "train_dataset=DataSet(map1_patch_dir_train,map2_patch_dir_train,mask_patch_dir_train,transform=transform)\n",
    "train_loader=DataLoader(train_dataset,batch_size=batch_size_train,num_workers=0,shuffle=True)\n",
    "print(train_dataset.__len__(),\" Train samples\")\n",
    "\n",
    "test_dataset=DataSet(map1_patch_dir_test,map2_patch_dir_test,mask_patch_dir_test,transform=transform)\n",
    "test_loader=DataLoader(test_dataset,batch_size=batch_size_test,num_workers=0,shuffle=False)\n",
    "print(test_dataset.__len__(),\" Test samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def dice_metric(y_pred,y_true):\n",
    "    smooth = 1\n",
    "    num = y_true.size(0)\n",
    "    m1 = y_pred.view(num, -1)\n",
    "    m2 = y_true.view(num, -1)\n",
    "    \n",
    "        \n",
    "    intersection = (m1* m2)\n",
    "\n",
    "    score = 2. * (intersection.sum(1) + smooth) / (m1.sum(1) + m2.sum(1) + smooth)\n",
    "    score = score.sum() / num\n",
    "        \n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_loader(loader,index):\n",
    "    for i,sample in enumerate(loader):\n",
    "        #print(sample['image'].shape)\n",
    "        if i==1:\n",
    "            map1=(sample['map1'][index]).numpy()\n",
    "            \n",
    "            \n",
    "            #image=np.zeros(image_i.shape,dtype=np.uint8)\n",
    "            #image[np.where(image_i!=0)]=255\n",
    "\n",
    "            map2=(sample['map2'][index]).numpy()\n",
    "            \n",
    "        \n",
    "            mask=(sample['mask'][index]).numpy()\n",
    "        \n",
    "           \n",
    "    \n",
    "            map1=map1.transpose(1,2,0)\n",
    "            map2=map2.transpose(1,2,0)\n",
    "            mask=np.squeeze(mask.transpose(1,2,0),axis=2)\n",
    "            print(map1.shape,np.amax(map1))\n",
    "        \n",
    "            fig=plt.figure()\n",
    "            plt.imshow(map1)\n",
    "            fig2=plt.figure()\n",
    "            plt.imshow(map2)\n",
    "            fig3=plt.figure()\n",
    "            plt.imshow(mask)\n",
    "            break\n",
    "visualize_loader(test_loader,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=DualEncoding_U_Net()\n",
    "model_start_date=datetime.datetime.now().strftime(\"%Y_%m_%d\")\n",
    "BEST_MODEL_PATH=os.path.join(os.getcwd(),'model_{}'.format(model_start_date))\n",
    "if not os.path.exists(BEST_MODEL_PATH):\n",
    "    os.mkdir(BEST_MODEL_PATH)\n",
    "    print('model_{} dir has been made'.format(model_start_date))\n",
    "print(\"Model's state_dict:\")\n",
    "writer = SummaryWriter('model_{}/experiment_{}'.format(model_start_date,1))\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "optimizer_selected='adam'\n",
    "batchsize=4\n",
    "no_steps=train_dataset.__len__()//batchsize\n",
    "restart_epochs=8\n",
    "num_epochs=10\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#criterion = SoftDiceLoss()#\n",
    "criterion=nn.BCELoss()\n",
    "\n",
    "history={'train_loss':[],'test_loss':[],'train_dice':[],'test_dice':[]}\n",
    "model = model.to(device)\n",
    "if optimizer_selected=='adam':\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=1e-03, betas=(0.9, 0.98))#,weight_decay=0.02)\n",
    "else:\n",
    "    optimizer = torch.optim.SGD(model.parameters(),lr=1e-03, momentum=0.8,nesterov=True)\n",
    "\n",
    "scheduler=torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, restart_epochs*no_steps,\\\n",
    "                                                     eta_min=1e-012, last_epoch=-1)\n",
    "\n",
    "\n",
    "best_val=0\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    print(\"Learning Rate : {}\".format(optimizer.state_dict()['param_groups'][-1]['lr']))\n",
    "    # loop over the dataset multiple times\n",
    "    \n",
    "    run_avg_train_loss=0\n",
    "    run_avg_train_dice=0\n",
    "    \n",
    "   \n",
    "    \n",
    "    run_avg_test_loss=0\n",
    "    run_avg_test_dice=0\n",
    "    \n",
    "    for mode in ['train','eval']:\n",
    "     \n",
    "        if mode == 'train':\n",
    "            \n",
    "            model.train()\n",
    "            loop=tqdm(train_loader)\n",
    "            \n",
    "            for i, sample_batched in (enumerate(loop)):\n",
    "                loop.set_description('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "                \n",
    "                #Clear Gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # get the inputs; data is a list of [dapi, nuclei, boundary]\n",
    "                map1_batch, map2_batch,mask_batch = sample_batched['map1'],\\\n",
    "                sample_batched['map2'],sample_batched['mask']\n",
    "                \n",
    "                map1_batch, map2_batch,mask_batch = map1_batch.to(device, dtype = torch.float)\\\n",
    "                ,map2_batch.to(device, dtype = torch.float),mask_batch.to(device,dtype=torch.float)\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = torch.sigmoid(model(map1_batch,map2_batch))\n",
    "                \n",
    "                loss = criterion(outputs, mask_batch)\n",
    "                dice_score=dice_metric(outputs,mask_batch)\n",
    "                run_avg_train_loss=(run_avg_train_loss*(0.9))+loss.detach().item()*0.1\n",
    "                run_avg_train_dice=(run_avg_train_dice*(0.9))+dice_score.detach().item()*0.1\n",
    "               \n",
    "                if i%100==99:\n",
    "                    \n",
    "                \n",
    "                    \n",
    "                    img_tensor=torch.cat((outputs.detach().cpu(),mask_batch.detach().cpu()),axis=0)\n",
    "                    \n",
    "                    \n",
    "            \n",
    "                    img_grid2 = torchvision.utils.make_grid(img_tensor*255,nrow=batch_size_train,padding=100)\n",
    "                    torchvision.utils.save_image(img_grid2,os.path.join(BEST_MODEL_PATH,\\\n",
    "                                                                        'train_iter_{}.png'\\\n",
    "                                                                        .format(epoch*len(train_loader)+i+1)))\n",
    "                    writer.add_image('TRAIN_ITER_{}'.format(epoch * len(train_loader) + i+1), img_grid2)\n",
    "                    \n",
    "                    \n",
    "                    writer.add_scalar('Training dice score nuclei',\n",
    "                            run_avg_train_dice,\n",
    "                            epoch * len(train_loader) + i+1)\n",
    "                \n",
    "                    writer.add_scalar('Training Loss',\n",
    "                            run_avg_train_loss,\n",
    "                            epoch * len(train_loader) + i+1)\n",
    "                    \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                scheduler.step()\n",
    "                \n",
    "                \n",
    "                loop.set_postfix(loss=run_avg_train_loss,dice_score=run_avg_train_dice)\n",
    "               \n",
    "            history['train_loss'].append(run_avg_train_loss)\n",
    "            history['train_dice'].append(run_avg_train_dice)\n",
    "                \n",
    "                 \n",
    "                    \n",
    "        elif mode =='eval':\n",
    "            #Clear Gradients\n",
    "            optimizer.zero_grad()\n",
    "            samples_test=len(test_loader)\n",
    "            model.eval()\n",
    "            val_loss=0\n",
    "            test_agg=0\n",
    "            for j, test_sample in enumerate(test_loader):\n",
    "\n",
    "                test_map1_batch, test_map2_mask_batch,test_mask_batch = test_sample['map1']\\\n",
    "                , test_sample['map2'],test_sample['mask']\n",
    "                \n",
    "                test_map1_batch, test_map2_mask_batch,test_mask_batch = test_map1_batch.to(device, dtype = torch.float),\\\n",
    "                test_map2_mask_batch.to(device, dtype = torch.float),test_mask_batch.to(device, dtype = torch.float)\n",
    "                test_outputs = torch.sigmoid(model(test_map1_batch,test_map2_batch))\n",
    "                \n",
    "                test_loss = criterion(test_outputs, test_mask_batch)\n",
    "                #final_test_loss+=test_loss.detach().item()\n",
    "                test_dice=dice_metric(test_outputs,test_mask_batch)\n",
    "                #final_test_dice+=test_dice\n",
    "                run_avg_test_loss=(run_avg_test_loss*(0.9))+test_loss.detach().item()*0.1\n",
    "                run_avg_test_dice=(run_avg_test_dice*(0.9))+test_dice.detach().item()*0.1\n",
    "               \n",
    "                if j%100==99:\n",
    "                    \n",
    "                    img_tensor_test=torch.cat((test_outputs.detach().cpu(),test_mask_batch.detach().cpu()),axis=0)\n",
    "                    \n",
    "                    \n",
    "                    img_grid = torchvision.utils.make_grid(img_tensor_test*255,nrow=batch_size_test,padding=10)\n",
    "                    torchvision.utils.save_image(img_grid,os.path.join(BEST_MODEL_PATH,\\\n",
    "                                                                        'test_iter_{}.png'\\\n",
    "                                                                        .format(epoch*len(test_loader)+j+1)))\n",
    "                    writer.add_image('TEST_ITER_{}'.format(epoch * len(test_loader) + j+1), img_grid)\n",
    "                    writer.add_scalar('Testing dice score ',\\\n",
    "                                      run_avg_test_dice,epoch * len(test_loader) + j+1)\n",
    "                    \n",
    "                    writer.add_scalar('Testing Loss',\\\n",
    "                                      run_avg_test_loss,epoch * len(test_loader) + j+1)\n",
    "                \n",
    "            print(\"test_loss: {}\\ntest_dice :{}\"\\\n",
    "                  .format(run_avg_test_loss,run_avg_test_dice))\n",
    "            history['test_loss'].append(run_avg_test_loss)\n",
    "            history['test_dice'].append(run_avg_test_dice)\n",
    "            if run_avg_test_dice>best_val:\n",
    "                best_val=run_avg_test_dice\n",
    "                torch.save(model.state_dict(), BEST_MODEL_PATH+'/model_optim.pth')\n",
    "                print(\"saved model with test dice score: {}\".format(best_val))\n",
    "\n",
    "        \n",
    "#             print(\"val_loss {}\".format(val_loss/samples_test))\n",
    "torch.save(model.state_dict(), BEST_MODEL_PATH+'/model_final.pth')\n",
    "print('Finished Training')\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
