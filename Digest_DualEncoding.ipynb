{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm \n",
    "\n",
    "import os, shutil\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import skimage\n",
    "from skimage.io import imread,imsave\n",
    "from skimage import morphology\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage import img_as_uint\n",
    "\n",
    "\n",
    "from digest_patchExtractor import DualPatchExtractor\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from models_pytorch import DualEncoding_U_Net,init_weights,save_model,load_model\n",
    "from DigestPath_Dataset import DataSet,ToTensor,Scale,Color\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "# from preprocess import fuse_roi,generate_train_mask\n",
    "# from prediction import whole_img_pred,post_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map1_dir_train='/home/vahadaneabhi01/datalab/training-assets/R_medical/atheeth/digest_new/colon_repo/digest_path/map_1_train/'\n",
    "map2_dir_train='/home/vahadaneabhi01/datalab/training-assets/R_medical/atheeth/digest_new/colon_repo/digest_path/map_2_train/'\n",
    "mask_dir_train='/home/vahadaneabhi01/datalab/training-assets/R_medical/atheeth/digest_new/colon_repo/digest_path/mask_train/'\n",
    "map1_patch_dir_train='/home/vahadaneabhi01/datalab/training-assets/R_medical/atheeth/digest_new/colon_repo/digest_path/map_1_patches_train/'\n",
    "map2_patch_dir_train='/home/vahadaneabhi01/datalab/training-assets/R_medical/atheeth/digest_new/colon_repo/digest_path/map_2_patches_train/'\n",
    "mask_patch_dir_train='/home/vahadaneabhi01/datalab/training-assets/R_medical/atheeth/digest_new/colon_repo/digest_path/mask_patches_train/'\n",
    "\n",
    "map1_dir_test='/home/vahadaneabhi01/datalab/training-assets/R_medical/atheeth/digest_new/colon_repo/digest_path/map_1_test/'\n",
    "map2_dir_test='/home/vahadaneabhi01/datalab/training-assets/R_medical/atheeth/digest_new/colon_repo/digest_path/map_2_test/'\n",
    "mask_dir_test='/home/vahadaneabhi01/datalab/training-assets/R_medical/atheeth/digest_new/colon_repo/digest_path/mask_test/'\n",
    "map1_patch_dir_test='/home/vahadaneabhi01/datalab/training-assets/R_medical/atheeth/digest_new/colon_repo/digest_path/map_1_patches_test/'\n",
    "map2_patch_dir_test='/home/vahadaneabhi01/datalab/training-assets/R_medical/atheeth/digest_new/colon_repo/digest_path/map_2_patches_test/'\n",
    "mask_patch_dir_test='/home/vahadaneabhi01/datalab/training-assets/R_medical/atheeth/digest_new/colon_repo/digest_path/mask_patches_test/'\n",
    "\n",
    "dir_list=[map1_dir_train,map2_dir_train,mask_dir_train,map1_patch_dir_train,\\\n",
    "          map2_patch_dir_train,mask_patch_dir_train,map1_dir_test,map2_dir_test,\\\n",
    "          mask_dir_test,map1_patch_dir_test,map2_patch_dir_test,mask_patch_dir_test]\n",
    "# for directory in dir_list:\n",
    "#     if not os.path.exists(directory):\n",
    "#         os.system(\"mkdir {}\".format(directory))\n",
    "#         print('made directory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "map_1_dir='map_1_gray_matlab'\n",
    "map_2_dir='map_2_gray_matlab'\n",
    "mask_dir='tissue-train-pos-v1_mask'\n",
    "\n",
    "all_img_list=os.listdir(map_1_dir)\n",
    "\n",
    "train_list=random.sample(all_img_list, 150)\n",
    "test_list=list(set(all_img_list)-set(train_list))\n",
    "# for train_img in tqdm(train_list):\n",
    "#     mask_img_name=train_img.split('.')[0]+'_mask.jpg'\n",
    "#     shutil.copy(os.path.join(map_1_dir,train_img),os.path.join(map1_dir_train,train_img))\n",
    "#     shutil.copy(os.path.join(map_2_dir,train_img),os.path.join(map2_dir_train,train_img))\n",
    "#     shutil.copy(os.path.join(mask_dir,mask_img_name),os.path.join(mask_dir_train,mask_img_name))\n",
    "    \n",
    "# for test_img in tqdm(test_list):\n",
    "#     test_mask_img_name=test_img.split('.')[0]+'_mask.jpg'\n",
    "#     shutil.copy(os.path.join(map_1_dir,test_img),os.path.join(map1_dir_test,test_img))\n",
    "#     shutil.copy(os.path.join(map_2_dir,test_img),os.path.join(map2_dir_test,test_img))\n",
    "#     shutil.copy(os.path.join(mask_dir,test_mask_img_name),os.path.join(mask_dir_test,test_mask_img_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train_extractor=DualPatchExtractor(map1_dir_train,map2_dir_train,mask_dir_train,map1_patch_dir_train,map2_patch_dir_train\\\n",
    "#                                ,mask_patch_dir_train,overlap=False,progress_bar=True)\n",
    "\n",
    "# train_extractor.extract_patches()\n",
    "\n",
    "# test_extractor=DualPatchExtractor(map1_dir_test,map2_dir_test,mask_dir_test,map1_patch_dir_test,map2_patch_dir_test\\\n",
    "#                                ,mask_patch_dir_test,overlap=False,progress_bar=True)\n",
    "\n",
    "# test_extractor.extract_patches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train=4\n",
    "batch_size_test=4\n",
    "transform=torchvision.transforms.Compose([Scale(),ToTensor()])    \n",
    "\n",
    "\n",
    "\n",
    "train_dataset=DataSet(map1_patch_dir_train,map2_patch_dir_train,mask_patch_dir_train,transform=transform)\n",
    "train_loader=DataLoader(train_dataset,batch_size=batch_size_train,num_workers=0,shuffle=True)\n",
    "print(train_dataset.__len__(),\" Train samples\")\n",
    "\n",
    "test_dataset=DataSet(map1_patch_dir_test,map2_patch_dir_test,mask_patch_dir_test,transform=transform)\n",
    "test_loader=DataLoader(test_dataset,batch_size=batch_size_test,num_workers=0,shuffle=False)\n",
    "print(test_dataset.__len__(),\" Test samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def dice_metric(y_pred,y_true):\n",
    "    smooth = 1e-16\n",
    "    num = y_true.size(0)\n",
    "    m1 = y_pred.view(num, -1)\n",
    "    m2 = y_true.view(num, -1)\n",
    "    \n",
    "        \n",
    "    intersection = (m1* m2)\n",
    "\n",
    "    score = 2. * (intersection.sum(1) + smooth) / (m1.sum(1) + m2.sum(1) + smooth)\n",
    "    score = score.sum() / num\n",
    "        \n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_loader(loader,index):\n",
    "    for i,sample in enumerate(loader):\n",
    "        #print(sample['image'].shape)\n",
    "        if i==1:\n",
    "            map1=(sample['map1'][index]).numpy()\n",
    "            \n",
    "            \n",
    "            #image=np.zeros(image_i.shape,dtype=np.uint8)\n",
    "            #image[np.where(image_i!=0)]=255\n",
    "\n",
    "            map2=(sample['map2'][index]).numpy()\n",
    "            \n",
    "        \n",
    "            mask=(sample['mask'][index]).numpy()\n",
    "        \n",
    "           \n",
    "    \n",
    "            map1=np.squeeze(map1.transpose(1,2,0),axis=2)\n",
    "            map2=np.squeeze(map2.transpose(1,2,0),axis=2)\n",
    "            mask=np.squeeze(mask.transpose(1,2,0),axis=2)\n",
    "            print(map1.shape,np.amax(map1))\n",
    "        \n",
    "            fig=plt.figure()\n",
    "            plt.imshow(map1,cmap='gray')\n",
    "            fig2=plt.figure()\n",
    "            plt.imshow(map2,cmap='gray')\n",
    "            fig3=plt.figure()\n",
    "            plt.imshow(mask,cmap='gray')\n",
    "            break\n",
    "visualize_loader(test_loader,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import init\n",
    "\n",
    "\n",
    "\n",
    "def init_weights(net, init_type='normal', gain=0.02):\n",
    "    def init_func(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n",
    "            if init_type == 'normal':\n",
    "                init.normal_(m.weight.data, 0.0, gain)\n",
    "            elif init_type == 'xavier':\n",
    "                init.xavier_normal_(m.weight.data, gain=gain)\n",
    "            elif init_type == 'kaiming':\n",
    "                init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "            elif init_type == 'orthogonal':\n",
    "                init.orthogonal_(m.weight.data, gain=gain)\n",
    "            else:\n",
    "                raise NotImplementedError('initialization method {} is not implemented in pytorch'.format(init_type))\n",
    "            if hasattr(m, 'bias') and m.bias is not None:\n",
    "                init.constant_(m.bias.data, 0.0)\n",
    "        elif classname.find('BatchNorm2d') != -1:\n",
    "            init.normal_(m.weight.data, 1.0, gain)\n",
    "            init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "    print('initialized network with {} initialization'.format(init_type))\n",
    "    net.apply(init_func)\n",
    "    \n",
    "    \n",
    "def save_model(model,optimizer,name,scheduler=None):\n",
    "    if scheduler==None:\n",
    "        checkpoint = {\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer' : optimizer.state_dict()}\n",
    "    else:\n",
    "        checkpoint = {\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "        'scheduler' : scheduler.state_dict()}\n",
    "\n",
    "    torch.save(checkpoint,name)\n",
    "\n",
    "def load_model(filename,model,optimizer=None,scheduler=None):\n",
    "    checkpoint=torch.load(filename)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    print(\"Done loading\")\n",
    "    if  optimizer:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        print(optimizer.state_dict()['param_groups'][-1]['lr'],' : Learning rate')\n",
    "    if  scheduler:\n",
    "        scheduler.load_state_dict(checkpoint['optimizer'])\n",
    "        print(scheduler.state_dict()['param_groups'][-1]['lr'],' : Learning rate')\n",
    "\n",
    "    \n",
    "class ASM(nn.Module):\n",
    "    def __init__(self,F_ip,F_int):\n",
    "        super().__init__()\n",
    "#         self.GlobalPool = nn.AvgPool2d(kernel_size=2,stride=2)\n",
    "        self.W_1x1 = nn.Conv2d(F_ip, F_int, kernel_size=1,stride=1,padding=0,bias=True)\n",
    "        self.batch_norm=nn.BatchNorm2d(F_int)\n",
    "      \n",
    "\n",
    "    def forward(self,map_1_fm,map_2_fm):\n",
    "        \n",
    "        x=torch.cat((map_1_fm,map_2_fm),dim=1)\n",
    "#         psi=self.GlobalPool(x)\n",
    "        x1=self.W_1x1(x)\n",
    "        psi=torch.sigmoid(x1)\n",
    "        psi=self.batch_norm(psi)\n",
    "        \n",
    "\n",
    "        return x1*psi\n",
    "    \n",
    "    \n",
    "class FFM(nn.Module):\n",
    "    \n",
    "    def __init__(self,F_int):\n",
    "        super().__init__()\n",
    "        self.W_x = nn.Sequential(\n",
    "        nn.Conv2d(F_int, F_int, kernel_size=3,stride=1,padding=1,bias=True),\n",
    "        nn.BatchNorm2d(F_int),\n",
    "        nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.GlobalPool = nn.AvgPool2d(kernel_size=2,stride=2)\n",
    "        self.W_1x1 = nn.Conv2d(F_int, F_int, kernel_size=1,stride=1,padding=0,bias=True)\n",
    "        self.batch_norm=nn.BatchNorm2d(F_int)\n",
    "      \n",
    "\n",
    "    def forward(self,map_1_fm,map_2_fm):\n",
    "        \n",
    "        x=torch.cat((map_1_fm,map_2_fm),dim=1)\n",
    "        x=self.W_x(x)\n",
    "        x=self.GlobalPool(x)\n",
    "        psi=self.W_1x1(x)\n",
    "        psi=torch.sigmoid(psi)\n",
    "        \n",
    "        x1=x*psi\n",
    "        \n",
    "\n",
    "        return x1+x\n",
    "    \n",
    "    \n",
    "class DualEncoding_U_Net(nn.Module):\n",
    "    def __init__(self,img_ch=3,output_ch=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "\n",
    "        self.Conv1_encoding_1 = conv_block(ch_in=img_ch,ch_out=64)\n",
    "        self.Conv2_encoding_1 = conv_block(ch_in=64,ch_out=128)\n",
    "        self.Conv3_encoding_1 = conv_block(ch_in=128,ch_out=256)\n",
    "        self.Conv4_encoding_1 = conv_block(ch_in=256,ch_out=512)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.Conv1_encoding_2 = conv_block(ch_in=img_ch,ch_out=64)\n",
    "        self.Conv2_encoding_2 = conv_block(ch_in=64,ch_out=128)\n",
    "        self.Conv3_encoding_2 = conv_block(ch_in=128,ch_out=256)\n",
    "        self.Conv4_encoding_2 = conv_block(ch_in=256,ch_out=512)\n",
    "        \n",
    "        self.ffm=FFM(1024)\n",
    "        \n",
    "        self.asm4=ASM(128,64)\n",
    "        self.asm3=ASM(256,128)\n",
    "        self.asm2=ASM(512,256)\n",
    "        self.asm1=ASM(1024,512)\n",
    "      \n",
    "        self.dropout=nn.Dropout(0.45)\n",
    "\n",
    "        self.Up5 = up_conv(ch_in=1024,ch_out=512)\n",
    "        self.Up_conv5 = nn.Sequential(nn.Conv2d(1024,512,kernel_size=1,stride=1,padding=1,bias=True),\n",
    "                                      nn.BatchNorm2d(512),\n",
    "                                      nn.ReLU(inplace=True))\n",
    "\n",
    "        self.Up4 = up_conv(ch_in=512,ch_out=256)\n",
    "        self.Up_conv4 = nn.Sequential(nn.Conv2d(512,256,kernel_size=1,stride=1,padding=0,bias=True),\n",
    "                                      nn.BatchNorm2d(256),\n",
    "                                      nn.ReLU(inplace=True))\n",
    "\n",
    "        self.Up3 = up_conv(ch_in=256,ch_out=128)\n",
    "        self.Up_conv3 = nn.Sequential(nn.Conv2d(256,128,kernel_size=1,stride=1,padding=0,bias=True),\n",
    "                                      nn.BatchNorm2d(128),\n",
    "                                      nn.ReLU(inplace=True))\n",
    "\n",
    "        self.Up2 = up_conv(ch_in=128,ch_out=64)\n",
    "        self.Up_conv2 = nn.Sequential(nn.Conv2d(128,64,kernel_size=1,stride=1,padding=0,bias=True),\n",
    "                                      nn.BatchNorm2d(64),\n",
    "                                      nn.ReLU(inplace=True))\n",
    "\n",
    "        self.Conv_1x1 = nn.Conv2d(64,output_ch,kernel_size=1,stride=1,padding=0)\n",
    "\n",
    "\n",
    "    def forward(self,x_h,x_e):\n",
    "        # encoding path\n",
    "        x_h1 = self.Conv1_encoding_1(x_h)\n",
    "        # N*64*512*512\n",
    "\n",
    "        x_h2 = self.Maxpool(x_h1)\n",
    "        x_h2 = self.Conv2_encoding_1(x_h2)\n",
    "        # N*128*256*256\n",
    "\n",
    "        x_h3 = self.Maxpool(x_h2)\n",
    "        x_h3 = self.Conv3_encoding_1(x_h3)\n",
    "        # N*256*128*128\n",
    "\n",
    "        x_h4 = self.Maxpool(x_h3)\n",
    "        x_h4 = self.Conv4_encoding_1(x_h4)\n",
    "        # N*512*64*64\n",
    "        \n",
    "        x_e1 = self.Conv1_encoding_2(x_e)\n",
    "        # N*64*512*512\n",
    "\n",
    "        x_e2 = self.Maxpool(x_e1)\n",
    "        x_e2 = self.Conv2_encoding_2(x_e2)\n",
    "        # N*128*256*256\n",
    "\n",
    "        x_e3 = self.Maxpool(x_e2)\n",
    "        x_e3 = self.Conv3_encoding_2(x_e3)\n",
    "        # N*256*128*128\n",
    "\n",
    "        x_e4 = self.Maxpool(x_e3)\n",
    "        x_e4 = self.Conv4_encoding_2(x_e4)\n",
    "        # N*512*64*64\n",
    "    \n",
    "        x5=self.ffm(x_h4,x_e4)\n",
    "        # N*1024*32*32\n",
    "        print(x5.size())\n",
    "        \n",
    "        # decoding + concat path\n",
    "        \n",
    "        d5 = self.Up5(x5)\n",
    "        # N*512*64*64\n",
    "        print(d5.size())\n",
    "        x4=self.asm1(x_h4,x_e4)\n",
    "        print(x4.size())\n",
    "        # N*512*64*64\n",
    "        d5 = torch.cat((x4,d5),dim=1)\n",
    "        # N*1024*64*64\n",
    "        d5 = self.Up_conv5(d5)\n",
    "        # N*512*64*64\n",
    "\n",
    "        d4 = self.Up4(d5)\n",
    "        # N*256*128*128\n",
    "        x3=self.asm2(x_h3,x_e3)\n",
    "        # N*256*128*128\n",
    "        d4 = torch.cat((x3,d4),dim=1)\n",
    "        # N*512*128*128\n",
    "        d4 = self.Up_conv4(d4)\n",
    "        # N*256*128*128\n",
    "\n",
    "        d3 = self.Up3(d4)\n",
    "        # N*128*256*256\n",
    "        x2=self.asm3(x_h2,x_e2)\n",
    "        # N*128*256*256\n",
    "        \n",
    "        d3 = torch.cat((x2,d3),dim=1)\n",
    "        # N*256*256*256\n",
    "        d3 = self.Up_conv3(d3)\n",
    "        # N*128*256*256\n",
    "\n",
    "        d2 = self.Up2(d3)\n",
    "        # N*64*512*512\n",
    "        x1=self.asm4(x_h1,x_e1)\n",
    "        # N*64*512*512\n",
    "        d2 = torch.cat((x1,d2),dim=1)\n",
    "        # N*128*512*512\n",
    "        d2 = self.Up_conv2(d2)\n",
    "        # N*64*512*512\n",
    "\n",
    "        d1 = self.Conv_1x1(d2)\n",
    "        # N*1*512*512\n",
    "\n",
    "        return d1\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=DualEncoding_U_Net(img_ch=1,output_ch=1)\n",
    "model_start_date=datetime.datetime.now().strftime(\"%Y_%m_%d\")\n",
    "BEST_MODEL_PATH=os.path.join(os.getcwd(),'model_{}'.format(model_start_date))\n",
    "if not os.path.exists(BEST_MODEL_PATH):\n",
    "    os.mkdir(BEST_MODEL_PATH)\n",
    "    print('model_{} dir has been made'.format(model_start_date))\n",
    "print(\"Model's state_dict:\")\n",
    "writer = SummaryWriter('model_{}/experiment_{}'.format(model_start_date,1))\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer_selected='adam'\n",
    "batchsize=4\n",
    "no_steps=train_dataset.__len__()//batchsize\n",
    "restart_epochs=5\n",
    "num_epochs=10\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device==\"cuda:0\":\n",
    "    print(torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "\n",
    "#criterion = SoftDiceLoss()#\n",
    "criterion=nn.BCELoss()\n",
    "\n",
    "history={'train_loss':[],'test_loss':[],'train_dice':[],'test_dice':[]}\n",
    "model = model.to(device)\n",
    "if optimizer_selected=='adam':\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=1e-02, betas=(0.9, 0.98))#,weight_decay=0.02)\n",
    "else:\n",
    "    optimizer = torch.optim.SGD(model.parameters(),lr=1e-03, momentum=0.8,nesterov=True)\n",
    "\n",
    "scheduler=torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, restart_epochs*no_steps,\\\n",
    "                                                     eta_min=1e-012, last_epoch=-1)\n",
    "\n",
    "\n",
    "best_val=0\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    print(\"Learning Rate : {}\".format(optimizer.state_dict()['param_groups'][-1]['lr']))\n",
    "    # loop over the dataset multiple times\n",
    "    \n",
    "    run_avg_train_loss=0\n",
    "    run_avg_train_dice=0\n",
    "    \n",
    "   \n",
    "    \n",
    "    run_avg_test_loss=0\n",
    "    run_avg_test_dice=0\n",
    "    \n",
    "    for mode in ['train','eval']:\n",
    "     \n",
    "        if mode == 'train':\n",
    "            \n",
    "            model.train()\n",
    "            loop=tqdm(train_loader)\n",
    "            \n",
    "            for i, sample_batched in (enumerate(loop)):\n",
    "                loop.set_description('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "                \n",
    "                #Clear Gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # get the inputs; data is a list of [dapi, nuclei, boundary]\n",
    "                map1_batch, map2_batch,mask_batch = sample_batched['map1'],\\\n",
    "                sample_batched['map2'],sample_batched['mask']\n",
    "                \n",
    "                map1_batch, map2_batch,mask_batch = map1_batch.to(device, dtype = torch.float)\\\n",
    "                ,map2_batch.to(device, dtype = torch.float),mask_batch.to(device,dtype=torch.float)\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = torch.sigmoid(model(map1_batch,map2_batch))\n",
    "                \n",
    "                loss = criterion(outputs, mask_batch)\n",
    "                dice_score=dice_metric(outputs,mask_batch)\n",
    "                run_avg_train_loss=(run_avg_train_loss*(0.9))+loss.detach().item()*0.1\n",
    "                run_avg_train_dice=(run_avg_train_dice*(0.9))+dice_score.detach().item()*0.1\n",
    "               \n",
    "                if i%100==99:\n",
    "                    \n",
    "                \n",
    "                    \n",
    "                    img_tensor=torch.cat((map1_batch.detach().cpu(),outputs.detach().cpu()\\\n",
    "                                          ,mask_batch.detach().cpu()),axis=0)\n",
    "                    \n",
    "                    \n",
    "            \n",
    "                    img_grid2 = torchvision.utils.make_grid(img_tensor*255,nrow=batch_size_train,padding=100)\n",
    "                    torchvision.utils.save_image(img_grid2,os.path.join(BEST_MODEL_PATH,\\\n",
    "                                                                        'train_iter_{}.png'\\\n",
    "                                                                        .format(epoch*len(train_loader)+i+1)))\n",
    "                    writer.add_image('TRAIN_ITER_{}'.format(epoch * len(train_loader) + i+1), img_grid2)\n",
    "                    \n",
    "                    \n",
    "                    writer.add_scalar('Training dice score nuclei',\n",
    "                            run_avg_train_dice,\n",
    "                            epoch * len(train_loader) + i+1)\n",
    "                \n",
    "                    writer.add_scalar('Training Loss',\n",
    "                            run_avg_train_loss,\n",
    "                            epoch * len(train_loader) + i+1)\n",
    "                    \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                scheduler.step()\n",
    "                \n",
    "                \n",
    "                loop.set_postfix(loss=run_avg_train_loss,dice_score=run_avg_train_dice)\n",
    "               \n",
    "            history['train_loss'].append(run_avg_train_loss)\n",
    "            history['train_dice'].append(run_avg_train_dice)\n",
    "                \n",
    "                 \n",
    "                    \n",
    "        elif mode =='eval':\n",
    "            #Clear Gradients\n",
    "            optimizer.zero_grad()\n",
    "            samples_test=len(test_loader)\n",
    "            model.eval()\n",
    "            val_loss=0\n",
    "            test_agg=0\n",
    "            for j, test_sample in enumerate(test_loader):\n",
    "\n",
    "                test_map1_batch, test_map2_batch,test_mask_batch = test_sample['map1']\\\n",
    "                , test_sample['map2'],test_sample['mask']\n",
    "                \n",
    "                test_map1_batch, test_map2_batch,test_mask_batch = test_map1_batch.to(device, dtype = torch.float),\\\n",
    "                test_map2_batch.to(device, dtype = torch.float),test_mask_batch.to(device, dtype = torch.float)\n",
    "                test_outputs = torch.sigmoid(model(test_map1_batch,test_map2_batch))\n",
    "                \n",
    "                test_loss = criterion(test_outputs, test_mask_batch)\n",
    "                #final_test_loss+=test_loss.detach().item()\n",
    "                test_dice=dice_metric(test_outputs,test_mask_batch)\n",
    "                #final_test_dice+=test_dice\n",
    "                run_avg_test_loss=(run_avg_test_loss*(0.9))+test_loss.detach().item()*0.1\n",
    "                run_avg_test_dice=(run_avg_test_dice*(0.9))+test_dice.detach().item()*0.1\n",
    "               \n",
    "                if j%100==99:\n",
    "                    \n",
    "                    img_tensor_test=torch.cat((test_map1_batch.detach().cpu(),\\\n",
    "                                               test_outputs.detach().cpu(),test_mask_batch.detach().cpu()),axis=0)\n",
    "                    \n",
    "                    \n",
    "                    img_grid = torchvision.utils.make_grid(img_tensor_test*255,nrow=batch_size_test,padding=10)\n",
    "                    torchvision.utils.save_image(img_grid,os.path.join(BEST_MODEL_PATH,\\\n",
    "                                                                        'test_iter_{}.png'\\\n",
    "                                                                        .format(epoch*len(test_loader)+j+1)))\n",
    "                    writer.add_image('TEST_ITER_{}'.format(epoch * len(test_loader) + j+1), img_grid)\n",
    "                    writer.add_scalar('Testing dice score ',\\\n",
    "                                      run_avg_test_dice,epoch * len(test_loader) + j+1)\n",
    "                    \n",
    "                    writer.add_scalar('Testing Loss',\\\n",
    "                                      run_avg_test_loss,epoch * len(test_loader) + j+1)\n",
    "                \n",
    "            print(\"test_loss: {}\\ntest_dice :{}\"\\\n",
    "                  .format(run_avg_test_loss,run_avg_test_dice))\n",
    "            history['test_loss'].append(run_avg_test_loss)\n",
    "            history['test_dice'].append(run_avg_test_dice)\n",
    "            if run_avg_test_dice>best_val:\n",
    "                best_val=run_avg_test_dice\n",
    "                save_model(model,optimizer,BEST_MODEL_PATH+'/model_optim.pth',scheduler=None)\n",
    "                \n",
    "                print(\"saved model with test dice score: {}\".format(best_val))\n",
    "\n",
    "        \n",
    "#             print(\"val_loss {}\".format(val_loss/samples_test))\n",
    "save_model(model,optimizer,BEST_MODEL_PATH+'/model_final.pth',scheduler=None)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
