{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1014 18:26:11.931169 140518152927040 deprecation_wrapper.py:119] From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W1014 18:26:11.936409 140518152927040 deprecation_wrapper.py:119] From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from skimage import morphology\n",
    "#import sys\n",
    "import scipy\n",
    "\n",
    "#import xml.etree.ElementTree as ET\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "#import imutils\n",
    "#import pandas as pd\n",
    "#import re\n",
    "import datetime\n",
    "\n",
    "import zipfile\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "from sklearn import metrics\n",
    "#from sklearn.utils import shuffle\n",
    "#from skimage import draw\n",
    "from skimage.io import imread\n",
    "\n",
    "#from sklearn.model_selection import train_test_split#import spams\n",
    "\n",
    "from skimage.util import pad\n",
    "import skimage\n",
    "\n",
    "import time\n",
    "import math\n",
    "import keras\n",
    "from keras.models import model_from_json\n",
    "#from keras.layers import *\n",
    "#from keras.preprocessing import image\n",
    "import keras.backend as K\n",
    "#import random\n",
    "#from sklearn.metrics import f1_score\n",
    "#from skimage.transform import resize\n",
    "from skimage.filters import threshold_otsu\n",
    "#from tqdm import tqdm_notebook as tqdm \n",
    "#from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "run_opts = tf.RunOptions(report_tensor_allocations_upon_oom = True)\n",
    "config = tf.ConfigProto()\n",
    "#config.gpu_options.per_process_gpu_memory_fraction=0.29\n",
    "config.gpu_options.allow_growth=True ##to use gpu as needed\n",
    "config.log_device_placement = True  \n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)\n",
    "K.tensorflow_backend._get_available_gpus()\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "a=np.zeros((8,512,512,1))\n",
    "a=np.squeeze(a)#np.rollaxis(a,3,0)#[0]\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Oct 14 18:26:12 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.39       Driver Version: 418.39       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:B1:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    53W / 300W |    318MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice(y_true, y_pred):\n",
    "    \n",
    "    y_true_f = (y_true).reshape((-1,1))\n",
    "    y_pred_f = np.round((y_pred).reshape((-1,1)))\n",
    "    \n",
    "\n",
    "    intersection = np.nansum(y_true_f * y_pred_f)+(np.finfo(float).eps)\n",
    "    union=np.nansum(y_true_f) + np.nansum(y_pred_f)\n",
    "    \n",
    "    dice= (2 * intersection) / ( union+ (np.finfo(float).eps))\n",
    "    return dice \n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \n",
    "    y_true_f = (y_true).reshape((-1,1))\n",
    "    y_pred_f = np.round((y_pred).reshape((-1,1)))\n",
    "    tp = np.nansum(y_true_f * y_pred_f)+(np.finfo(float).eps)\n",
    "    fn=np.nansum((1-y_pred_f)*y_true_f)+(np.finfo(float).eps)\n",
    "    recall= tp/(tp+fn+np.finfo(float).eps)\n",
    "    return recall\n",
    "\n",
    "# def auc(y_true, y_pred):\n",
    "#     #y_true_f = K.flatten(y_true)\n",
    "#     #y_pred_f = K.flatten(y_pred)\n",
    "#     auc = tf.metrics.auc(y_true, y_pred,curve='PR',summation_method=\"careful_interpolation\")[1]\n",
    "#     K.get_session().run(tf.local_variables_initializer())\n",
    "#     return auc\n",
    "\n",
    "# def cm (y_true, y_pred):\n",
    "    \n",
    "#     auc = tf.metrics.auc(y_true, y_pred,curve='PR',summation_method=\"careful_interpolation\")[1]\n",
    "#     K.get_session().run(tf.local_variables_initializer())\n",
    "    \n",
    "#     y_true_f = K.flatten(y_true)\n",
    "#     y_pred_f = K.flatten(y_pred)\n",
    "    \n",
    "#     intersection = K.sum(y_true_f * y_pred_f)\n",
    "#     union=K.sum(y_true_f) + K.sum(y_pred_f)\n",
    "    \n",
    "#     dice= (2. * intersection) / ( union+ K.epsilon())\n",
    "    \n",
    "#     return (dice*100+auc*100)/2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available models are : ['model_2019_08_16', 'model_2019_08_21', 'model_2019_08_23', 'model_2019_08_26', 'model_2019_08_27', 'model_2019_08_29', 'model_2019_08_30', 'model_2019_09_19', 'model_2019_09_21'] \n",
      " selected model is in : /datalab/digest/Colonoscopy_tissue_segment_dataset/model_2019_08_29\n",
      "Selected model file is : model_final_weights_2019_08_29.h5\n",
      "Selected architecture file is : model_2019_08_29.json\n"
     ]
    }
   ],
   "source": [
    "dir_content=os.listdir(os.getcwd())\n",
    "model_list=[s for s in dir_content if 'model_2019' in s]\n",
    "model_list=sorted(model_list)\n",
    "model_folder=os.path.join(os.getcwd(),model_list[-4])\n",
    "print(\"available models are :\",model_list,\"\\n\",\"selected model is in :\", model_folder)\n",
    "model_weights=os.path.join(os.getcwd(),model_folder)+\"/\"+[weights for weights in os.listdir(model_folder) \\\n",
    "                                                          if 'model_' in weights][-1]\n",
    "model_architecture=glob.glob(os.path.join(os.getcwd(),model_folder)+\"/*.json\")[-1]\n",
    "print(\"Selected model file is : {}\\nSelected architecture file is : {}\".format(model_weights.split('/')[-1]\\\n",
    "                                                                          ,model_architecture.split('/')[-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1014 18:26:13.850787 140518152927040 deprecation_wrapper.py:119] From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1014 18:26:13.887876 140518152927040 deprecation_wrapper.py:119] From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "W1014 18:26:13.950279 140518152927040 deprecation_wrapper.py:119] From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W1014 18:26:14.017348 140518152927040 deprecation_wrapper.py:119] From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:131: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1014 18:26:14.026925 140518152927040 deprecation.py:506] From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1014 18:26:14.059281 140518152927040 deprecation_wrapper.py:119] From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W1014 18:26:14.238600 140518152927040 deprecation_wrapper.py:119] From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "W1014 18:26:33.344733 140518152927040 deprecation_wrapper.py:119] From /opt/conda/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1014 18:26:33.360848 140518152927040 deprecation.py:323] From /home/vahadaneabhi01/.local/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 512, 512, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 512, 512, 64) 1792        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 512, 512, 64) 36928       conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 256, 256, 64) 0           conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 256, 256, 128 73856       max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 256, 256, 128 147584      conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 128, 128, 128 0           conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 128, 128, 256 295168      max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 128, 128, 256 590080      conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 64, 64, 256)  0           conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 64, 64, 512)  1180160     max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 64, 64, 512)  2359808     conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 64, 64, 512)  0           conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 64, 64, 1024) 525312      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 64, 64, 1024) 4096        conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 64, 64, 1024) 0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 64, 64, 512)  524800      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_10 (Conv2DTran (None, 64, 64, 512)  2359808     conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 64, 64, 512)  524800      conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 64, 64, 512)  0           conv2d_transpose_10[0][0]        \n",
      "                                                                 conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 64, 64, 512)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 64, 64, 1)    513         activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 64, 64, 1)    0           conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_19 (UpSampling2D) (None, 128, 128, 1)  0           activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 128, 128, 256 0           up_sampling2d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "multiply_10 (Multiply)          (None, 128, 128, 256 0           lambda_10[0][0]                  \n",
      "                                                                 conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 128, 128, 256 65792       multiply_10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_20 (UpSampling2D) (None, 128, 128, 512 0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 128, 128, 256 1024        conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 128, 128, 256 524544      up_sampling2d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 128, 128, 512 0           batch_normalization_20[0][0]     \n",
      "                                                                 conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 128, 128, 256 1179904     concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 128, 128, 256 590080      conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 128, 128, 512 131584      conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 128, 128, 512 2048        conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 128, 128, 512 0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 128, 128, 256 131328      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_11 (Conv2DTran (None, 128, 128, 256 590080      conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 128, 128, 256 131328      conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 128, 128, 256 0           conv2d_transpose_11[0][0]        \n",
      "                                                                 conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 128, 128, 256 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 128, 128, 1)  257         activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 128, 128, 1)  0           conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_21 (UpSampling2D) (None, 256, 256, 1)  0           activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 256, 256, 128 0           up_sampling2d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "multiply_11 (Multiply)          (None, 256, 256, 128 0           lambda_11[0][0]                  \n",
      "                                                                 conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 256, 256, 128 16512       multiply_11[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_22 (UpSampling2D) (None, 256, 256, 256 0           conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 256, 256, 128 512         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 256, 256, 128 131200      up_sampling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 256, 256, 256 0           batch_normalization_22[0][0]     \n",
      "                                                                 conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 256, 256, 128 295040      concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 256, 256, 128 147584      conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 256, 256, 256 33024       conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 256, 256, 256 1024        conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 256, 256, 256 0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 256, 256, 128 32896       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_12 (Conv2DTran (None, 256, 256, 128 147584      conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 256, 256, 128 32896       conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 256, 256, 128 0           conv2d_transpose_12[0][0]        \n",
      "                                                                 conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 256, 256, 128 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 256, 256, 1)  129         activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 256, 256, 1)  0           conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_23 (UpSampling2D) (None, 512, 512, 1)  0           activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 512, 512, 64) 0           up_sampling2d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "multiply_12 (Multiply)          (None, 512, 512, 64) 0           lambda_12[0][0]                  \n",
      "                                                                 conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 512, 512, 64) 4160        multiply_12[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_24 (UpSampling2D) (None, 512, 512, 128 0           conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 512, 512, 64) 256         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 512, 512, 64) 32832       up_sampling2d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 512, 512, 128 0           batch_normalization_24[0][0]     \n",
      "                                                                 conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 512, 512, 64) 73792       concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 512, 512, 64) 36928       conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 512, 512, 2)  1154        conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 512, 512, 1)  3           conv2d_135[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 12,960,200\n",
      "Trainable params: 12,955,720\n",
      "Non-trainable params: 4,480\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "json_file = open(model_architecture, 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "OPT=keras.optimizers.SGD(lr=0.01,momentum=0.8,nesterov=True)\n",
    "loaded_model.load_weights(model_weights)\n",
    "loaded_model.compile(optimizer = OPT, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "print(loaded_model.metrics_names)\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from skimage import img_as_uint\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "def combined_metric(y_true, y_pred):\n",
    "    \n",
    "    y_true_f = (y_true).reshape((-1,1))\n",
    "    y_pred_f = np.round((y_pred).reshape((-1,1)))\n",
    "    \n",
    "    \n",
    "    p,r,_=metrics.precision_recall_curve(y_true_f, y_pred_f)\n",
    "    auc=metrics.auc(p,r)\n",
    "    \n",
    "    intersection = np.nansum(y_true_f * y_pred_f)+(np.finfo(float).eps)\n",
    "    union=np.nansum(y_true_f) + np.nansum(y_pred_f)\n",
    "    \n",
    "    dice= (2 * intersection) / ( union+ (np.finfo(float).eps))\n",
    "    \n",
    "    \n",
    "    \n",
    "    return (dice*100+auc*100)/2\n",
    "\n",
    "def whole_img_pred(IMAGE_PATH,img_list,pred_dir_name,MASK_PATH=None,cal_performace=True):\n",
    "    samples_per_step=5\n",
    "    \n",
    "    pred_dir=os.path.join(os.getcwd(),pred_dir_name)\n",
    "    \n",
    "    if not os.path.exists(pred_dir):\n",
    "        os.mkdir(pred_dir)\n",
    "        print(\"Made {} directory\".format(pred_dir.split('/')[-1]))\n",
    "    else:\n",
    "        print(\"{} directory already exists in {}\".format(pred_dir.split('/')[-1],'/'.join(pred_dir.split('/')[:-1])))\n",
    "        \n",
    "        \n",
    "\n",
    "    avg_score=0\n",
    "    test_num=len(img_list)\n",
    "    for img_name in [img_list[1]]:\n",
    "        print(img_name)\n",
    "        str_time=time.time()\n",
    "\n",
    "        img=imread(os.path.join(IMAGE_PATH,img_name))\n",
    "        r,c,_=img.shape#4663,3881\n",
    "      \n",
    "        new_r_count=(math.ceil((r-512)/512)+1)#10\n",
    "        new_c_count=(math.ceil((c-512)/512)+1)#8\n",
    "\n",
    "\n",
    "        pad_r1=((new_r_count-1)*512-r+512)//2 #228\n",
    "        pad_r2=((new_r_count-1)*512-r+512)-pad_r1 #229\n",
    "        pad_c1=((new_c_count-1)*512-c+512)//2 #107\n",
    "        pad_c2=((new_c_count-1)*512-c+512)-pad_c1#108\n",
    "\n",
    "        arr_in=np.pad(img, [(pad_r1,pad_r2),(pad_c1,pad_c2),(0,0)], 'constant', constant_values=0)/255\n",
    "        print(arr_in.shape)\n",
    "        \n",
    "        window_shape=(512,512,3)\n",
    "        arr_out=skimage.util.view_as_windows(arr_in, window_shape, step=512)\n",
    "        x,y=arr_out.shape[:2]\n",
    "        print(x,y)\n",
    "        ar2=arr_out.reshape((-1,512,512,3))\n",
    "        del arr_out,arr_in,img\n",
    "        y_count=0\n",
    "        img_temp=[]\n",
    "        #y_pred=np.empty()\n",
    "        check=True\n",
    "        i_prev=0\n",
    "        y_iter=y//samples_per_step\n",
    "        y_iter_counter=1\n",
    "        y_dif=y-y_iter\n",
    "        for i in range(math.ceil(x*y/samples_per_step)):\n",
    "            if (i)*samples_per_step<y_iter:\n",
    "                if check:\n",
    "                    y_pred=np.concatenate(loaded_model.predict(ar2[i*samples_per_step:\\\n",
    "                                                                   (i+1)*samples_per_step]),axis=1)\n",
    "                    check=False\n",
    "                    print(y_pred.shape,\"Check1\",i)\n",
    "                else:\n",
    "                    y_pred=np.append(y_pred,np.concatenate(loaded_model.predict(ar2[i*samples_per_step:(i+1)*\\\n",
    "                                                                                    samples_per_step]),axis=1),axis=1)\n",
    "                    print(y_pred.shape,\"Check2\",i)\n",
    "            else:\n",
    "                y_pred=np.append(y_pred,np.concatenate(loaded_model.predict(ar2[(i)*samples_per_step:\\\n",
    "                                                                                (i)*samples_per_step+y_dif\\\n",
    "                                                                           ]),axis=1),axis=1)\n",
    "                print(\"row {} :{}\".format(i,y_pred.shape))\n",
    "                img_temp.append(y_pred)\n",
    "                check=True\n",
    "                del y_pred\n",
    "                y_iter_counter+=1\n",
    "                y_iter*=y_iter_counter\n",
    "                \n",
    "        img_temp=np.array(img_temp,dtype=np.float_)\n",
    "        print(img_temp.shape,'Check4')\n",
    "        img_temp=np.concatenate(img_temp,axis=0)\n",
    "        print(img_temp.shape,\"Check5\")\n",
    "        img_temp=img_temp[pad_r1:img_temp.shape[0]-pad_r2,pad_c1:img_temp.shape[1]-pad_c2,:]*255\n",
    "        print(img_temp.shape,\"Check6\")\n",
    "        #thresh = threshold_otsu(img_temp)\n",
    "        #img_temp = np.array(img_temp > thresh,dtype=np.float32)\n",
    "        pred_img_name=img_name.split('.')[0]+'_pred.jpg'\n",
    "        pred_img_path=os.path.join(pred_dir,pred_img_name)\n",
    "        skimage.io.imsave(pred_img_path,img_as_uint(img_temp))\n",
    "        print(\"time for {} shaped {} is {} s\".format((r,c),img_name,time.time()-str_time))\n",
    "        if cal_performace:\n",
    "            mask_path=os.path.join(MASK_PATH,img_name.split('.')[0]+'_mask.jpg')\n",
    "            mask=imread(mask_path,as_gray=True)//255\n",
    "            score=combined_metric(mask, img_temp)\n",
    "            avg_score+=score\n",
    "            print(\"Score : {}\".format(score))\n",
    "        del img_temp,ar2\n",
    "        if cal_performace:\n",
    "            del mask\n",
    "    if cal_performace:\n",
    "        print(\"Average Score : {}\".format(avg_score/test_num))\n",
    "    \n",
    "    print(\"DONE\")\n",
    "        \n",
    "MASK_PATH='/home/vahadaneabhi01/datalab/digest/Colonoscopy_tissue_segment_dataset/tissue-train-pos-v1_mask'\n",
    "IMAGE_PATH='/home/vahadaneabhi01/datalab/digest/Colonoscopy_tissue_segment_dataset/tissue-train-pos-v1_color_normalized'\n",
    "\n",
    "#NEG_IMAGE_PATH='/datalab/digest/Colonoscopy_tissue_segment_dataset/tissue-train-neg'\n",
    "#neg_img_list=os.listdir(NEG_IMAGE_PATH)\n",
    "\n",
    "all_img_list=os.listdir(IMAGE_PATH)\n",
    "INPUT_IMAGE_PATH_TEST='/home/vahadaneabhi01/datalab/digest/Colonoscopy_tissue_segment_dataset/input_cn_overlap_test'\n",
    "\n",
    "\n",
    "test_files=os.listdir(INPUT_IMAGE_PATH_TEST)\n",
    "test_img_list=['_'.join(x.split('_')[:-2])+'.jpg' for x in test_files]\n",
    "\n",
    "\n",
    "#whole_img_pred(IMAGE_PATH,test_img_list,'whole_pred_{}'.format(datetime.datetime.now().strftime(\"%Y_%m_%d\")),\\\n",
    "#               MASK_PATH,cal_performace=True)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from skimage import img_as_uint\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "def combined_metric(y_true, y_pred):\n",
    "    \n",
    "    y_true_f = (y_true).reshape((-1,1))\n",
    "    y_pred_f = np.round((y_pred).reshape((-1,1)))\n",
    "    \n",
    "    \n",
    "    p,r,_=metrics.precision_recall_curve(y_true_f, y_pred_f)\n",
    "    auc=metrics.auc(p,r)\n",
    "    \n",
    "    intersection = np.nansum(y_true_f * y_pred_f)+(np.finfo(float).eps)\n",
    "    union=np.nansum(y_true_f) + np.nansum(y_pred_f)\n",
    "    \n",
    "    dice= (2 * intersection) / ( union+ (np.finfo(float).eps))\n",
    "    \n",
    "    \n",
    "    \n",
    "    return (dice*100+auc*100)/2\n",
    "\n",
    "def whole_img_pred(IMAGE_PATH,img_list,pred_dir_name,MASK_PATH=None,cal_performace=True):\n",
    "    samples_per_step=5\n",
    "    \n",
    "    pred_dir=os.path.join(os.getcwd(),pred_dir_name)\n",
    "    \n",
    "    if not os.path.exists(pred_dir):\n",
    "        os.mkdir(pred_dir)\n",
    "        print(\"Made {} directory\".format(pred_dir.split('/')[-1]))\n",
    "    else:\n",
    "        print(\"{} directory already exists in {}\".format(pred_dir.split('/')[-1],'/'.join(pred_dir.split('/')[:-1])))\n",
    "        \n",
    "        \n",
    "\n",
    "    avg_score=0\n",
    "    test_num=len(img_list)\n",
    "    for img_name in [img_list[1]]:\n",
    "        print(img_name)\n",
    "        str_time=time.time()\n",
    "\n",
    "        img=imread(os.path.join(IMAGE_PATH,img_name))\n",
    "        r,c,_=img.shape#4663,3881\n",
    "      \n",
    "        new_r_count=(math.ceil((r-512)/512)+1)#10\n",
    "        new_c_count=(math.ceil((c-512)/512)+1)#8\n",
    "\n",
    "\n",
    "        pad_r1=((new_r_count-1)*512-r+512)//2 #228\n",
    "        pad_r2=((new_r_count-1)*512-r+512)-pad_r1 #229\n",
    "        pad_c1=((new_c_count-1)*512-c+512)//2 #107\n",
    "        pad_c2=((new_c_count-1)*512-c+512)-pad_c1#108\n",
    "\n",
    "        arr_in=np.pad(img, [(pad_r1,pad_r2),(pad_c1,pad_c2),(0,0)], 'constant', constant_values=0)/255\n",
    "        print(arr_in.shape)\n",
    "        \n",
    "        window_shape=(512,512,3)\n",
    "        arr_out=skimage.util.view_as_windows(arr_in, window_shape, step=512)\n",
    "        x,y=arr_out.shape[:2]\n",
    "        print(x,y)\n",
    "        ar2=arr_out.reshape((-1,512,512,3))\n",
    "        del arr_out,arr_in,img\n",
    "        y_count=0\n",
    "        img_temp=[]\n",
    "        #y_pred=np.empty()\n",
    "        check=True\n",
    "        i_prev=0\n",
    "        y_iter=y//samples_per_step\n",
    "        y_iter_counter=1\n",
    "        y_dif=y-y_iter\n",
    "        for i in range(x):\n",
    "            for j in range(y):\n",
    "                if j<y_iter\n",
    "                    if j==0:\n",
    "                        y_pred=np.concatenate(loaded_model.predict(ar2[i*samples_per_step:\\\n",
    "                                                                       (i+1)*samples_per_step]),axis=1)\n",
    "                        check=False\n",
    "                        print(y_pred.shape,\"Check1\",i)\n",
    "                    else:\n",
    "                        y_pred=np.append(y_pred,np.concatenate(loaded_model.predict(ar2[i*samples_per_step:(i+1)*\\\n",
    "                                                                                        samples_per_step]),axis=1),axis=1)\n",
    "                        print(y_pred.shape,\"Check2\",i)\n",
    "                else:\n",
    "                    y_pred=np.append(y_pred,np.concatenate(loaded_model.predict(ar2[(i)*samples_per_step:\\\n",
    "                                                                                    (i)*samples_per_step+y_dif\\\n",
    "                                                                               ]),axis=1),axis=1)\n",
    "                    print(\"row {} :{}\".format(i,y_pred.shape))\n",
    "                    img_temp.append(y_pred)\n",
    "                    check=True\n",
    "                    del y_pred\n",
    "                    y_iter_counter+=1\n",
    "                    y_iter*=y_iter_counter\n",
    "                \n",
    "        img_temp=np.array(img_temp,dtype=np.float_)\n",
    "        print(img_temp.shape,'Check4')\n",
    "        img_temp=np.concatenate(img_temp,axis=0)\n",
    "        print(img_temp.shape,\"Check5\")\n",
    "        img_temp=img_temp[pad_r1:img_temp.shape[0]-pad_r2,pad_c1:img_temp.shape[1]-pad_c2,:]*255\n",
    "        print(img_temp.shape,\"Check6\")\n",
    "        thresh = threshold_otsu(img_temp)\n",
    "        img_temp = np.array(img_temp > thresh,dtype=np.float32)\n",
    "        pred_img_name=img_name.split('.')[0]+'_pred.jpg'\n",
    "        pred_img_path=os.path.join(pred_dir,pred_img_name)\n",
    "        skimage.io.imsave(pred_img_path,img_as_uint(img_temp))\n",
    "        print(\"time for {} shaped {} is {} s\".format((r,c),img_name,time.time()-str_time))\n",
    "        if cal_performace:\n",
    "            mask_path=os.path.join(MASK_PATH,img_name.split('.')[0]+'_mask.jpg')\n",
    "            mask=imread(mask_path,as_gray=True)//255\n",
    "            score=combined_metric(mask, img_temp)\n",
    "            avg_score+=score\n",
    "            print(\"Score : {}\".format(score))\n",
    "        del img_temp,ar2\n",
    "        if cal_performace:\n",
    "            del mask\n",
    "    if cal_performace:\n",
    "        print(\"Average Score : {}\".format(avg_score/test_num))\n",
    "    \n",
    "    print(\"DONE\")\n",
    "        \n",
    "MASK_PATH='/home/vahadaneabhi01/datalab/digest/Colonoscopy_tissue_segment_dataset/tissue-train-pos-v1_mask'\n",
    "IMAGE_PATH='/home/vahadaneabhi01/datalab/digest/Colonoscopy_tissue_segment_dataset/tissue-train-pos-v1_color_normalized'\n",
    "\n",
    "#NEG_IMAGE_PATH='/datalab/digest/Colonoscopy_tissue_segment_dataset/tissue-train-neg'\n",
    "#neg_img_list=os.listdir(NEG_IMAGE_PATH)\n",
    "\n",
    "all_img_list=os.listdir(IMAGE_PATH)\n",
    "INPUT_IMAGE_PATH_TEST='/home/vahadaneabhi01/datalab/digest/Colonoscopy_tissue_segment_dataset/input_cn_overlap_test'\n",
    "\n",
    "\n",
    "test_files=os.listdir(INPUT_IMAGE_PATH_TEST)\n",
    "test_img_list=['_'.join(x.split('_')[:-2])+'.jpg' for x in test_files]\n",
    "\n",
    "\n",
    "#whole_img_pred(IMAGE_PATH,test_img_list,'whole_pred_{}'.format(datetime.datetime.now().strftime(\"%Y_%m_%d\")),\\\n",
    "              # MASK_PATH,cal_performace=True)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snnmf(I):\n",
    "    \n",
    "    I_lab_space = cv2.cvtColor(I, cv2.COLOR_RGB2LAB)\n",
    "    luminosity = I_lab_space[:, :, 0] \n",
    "    mask_lumin = luminosity/ 255 < 0.8\n",
    "    \n",
    "    mask_zero = (I == 0)\n",
    "    I[mask_zero] = 1\n",
    "    \n",
    "    od = (np.maximum(-1 * np.log(I / 255), 1e-6))\n",
    "    od_dl = od[mask_lumin]\n",
    "    od=od.reshape((-1, 3))\n",
    "    od_dl=od_dl.reshape((-1, 3))\n",
    "\n",
    "    dictionary = spams.trainDL(X=od_dl.T, K=2, lambda1=0.1, mode=2,\n",
    "                               modeD=0, posAlpha=True, posD=True, verbose=False).T\n",
    "\n",
    "    # dictionary is 2 x 3\n",
    "    #First one should be Hematoxylin(Bluish-purple)\n",
    "    if dictionary[0, 0] < dictionary[1, 0]:\n",
    "        dictionary = dictionary[[1, 0], :]\n",
    "\n",
    "    dictionary=dictionary / np.linalg.norm(dictionary, axis=1)[:, None]\n",
    "    \n",
    "    sparse=spams.lasso(X=od.T, D=dictionary.T, mode=2, lambda1=0.01, pos=True).toarray().T\n",
    "    \n",
    "    return dictionary,sparse\n",
    "\n",
    "def h_norm(hs,ht):\n",
    "    \n",
    "    ht_rm=np.percentile(ht, 99, axis=0).reshape(1,2)\n",
    "    hs_rm=np.percentile(hs, 99, axis=0).reshape(1,2)\n",
    "    \n",
    "    hs_norm_mat=hs*ht_rm/hs_rm\n",
    "    return hs_norm_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import img_as_uint\n",
    "import random\n",
    "import csv\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "def whole_img_pred(IMAGE_PATH,img_list,pred_dir_name,MASK_PATH=None,cal_performace=True):\n",
    "    samples_per_step=5\n",
    "    threshold=0.8\n",
    "    \n",
    "    pred_dir=os.path.join(os.getcwd(),pred_dir_name)\n",
    "    \n",
    "    if not os.path.exists(pred_dir):\n",
    "        os.mkdir(pred_dir)\n",
    "        print(\"Made {} directory\".format(pred_dir.split('/')[-1]))\n",
    "    else:\n",
    "        print(\"{} directory already exists in {}\".format(pred_dir.split('/')[-1],'/'.join(pred_dir.split('/')[:-1])))\n",
    "        \n",
    "    #imgt=imread(os.path.join(TARGET_PATH,'18-00530B_2019-05-07 23_56_22-lv1-11712-16122-7372-7686.jpg'))    \n",
    "    #wt,ht=snnmf(imgt)\n",
    "    avg_score=0\n",
    "    test_num=len(img_list)\n",
    "    random.shuffle(img_list)\n",
    "    iterations=2\n",
    "    lines=[]\n",
    "    for img_name in img_list:\n",
    "        #print(img_name)\n",
    "        str_time=time.time()\n",
    "\n",
    "        #imgs=imread(os.path.join(IMAGE_PATH,img_name))\n",
    "        img=imread(os.path.join(IMAGE_PATH,img_name))\n",
    "        #ws,hs=snnmf(imgs)\n",
    "        \n",
    "        #hs_norm=h_norm(hs,ht)\n",
    "        #od_recon=255 * np.exp(-1 * np.dot(hs_norm, wt))\n",
    "        #img=od_recon.reshape(imgs.shape).astype(np.uint8)\n",
    "        \n",
    "        r,c,_=img.shape#4663,3881\n",
    "      \n",
    "        new_r_count=(math.ceil((r-512)/512)+1)#10\n",
    "        new_c_count=(math.ceil((c-512)/512)+1)#8\n",
    "\n",
    "\n",
    "        pad_r1=((new_r_count-1)*512-r+512)//2 #228\n",
    "        \n",
    "        pad_r2=((new_r_count-1)*512-r+512)-pad_r1 #229\n",
    "        pad_c1=((new_c_count-1)*512-c+512)//2 #107\n",
    "        pad_c2=((new_c_count-1)*512-c+512)-pad_c1#108\n",
    "        \n",
    "\n",
    "        arr_in=np.pad(img, [(pad_r1,pad_r2),(pad_c1,pad_c2),(0,0)], 'constant', constant_values=0)/255\n",
    "        \n",
    "        \n",
    "        window_shape=(512,512,3)\n",
    "        arr_out=skimage.util.view_as_windows(arr_in, window_shape, step=512)\n",
    "        x,y=arr_out.shape[:2]\n",
    "        ar2=arr_out.reshape((-1,512,512,3))\n",
    "        del arr_out,arr_in,img\n",
    "        img_temp=[]\n",
    "        check=True\n",
    "        y_iter=y//samples_per_step\n",
    "        y_dif=y%5\n",
    "        i=0\n",
    "        i_temp=0\n",
    "        count=0\n",
    "        while i <=(x*y):\n",
    "            \n",
    "            if i_temp<y_iter or y_iter==0:                \n",
    "                if i_temp==0:\n",
    "                    y_pred=np.concatenate(loaded_model.predict(ar2[i:i+samples_per_step]),axis=1)\n",
    "                else:\n",
    "                    y_pred=np.append(y_pred,np.concatenate(loaded_model.predict(ar2[i:i+samples_per_step]),axis=1),axis=1)\n",
    "                i+=5\n",
    "                i_temp+=1\n",
    "                \n",
    "                    \n",
    "            else:\n",
    "                count+=1\n",
    "            \n",
    "                if count==x:\n",
    "                    break\n",
    "                    \n",
    "                if y_dif!=0:\n",
    "                    y_pred=np.append(y_pred,np.concatenate(loaded_model.predict(ar2[i:i+y_dif]),axis=1),axis=1)\n",
    "                    i+=y_dif\n",
    "                img_temp.append(y_pred)\n",
    "        \n",
    "                \n",
    "                i_temp=0\n",
    "                del y_pred                    \n",
    "                \n",
    "        img_temp=np.array(img_temp,dtype=np.float_)\n",
    "        img_temp=np.concatenate(img_temp,axis=0)\n",
    "        img_temp=np.squeeze(img_temp[pad_r1:img_temp.shape[0]-pad_r2,pad_c1:img_temp.shape[1]-pad_c2,:],axis=2)#*255\n",
    "    \n",
    "        img_prob=img_temp[img_temp>=0.4]\n",
    "        img_pos_pixels=img_prob[img_prob>=threshold]\n",
    "        img_neg_pixels=img_prob[img_prob<threshold]\n",
    "        prob_temp=len(img_pos_pixels)/len(img_prob)\n",
    "        if prob_temp>0.4:\n",
    "            prob_score=np.max(img_pos_pixels)\n",
    "        else:\n",
    "            prob_score=np.min(img_neg_pixels)\n",
    "            \n",
    "        #print(prob_score,\" prob\")\n",
    "        \n",
    "        #(((np.mean(img_pos_pixels)/len(img_pos_pixels)))+((np.mean(img_neg_pixels)/len(img_neg_pixels))))*len(img_prob)\n",
    "        #(np.sum(img_pos_pixels)+np.sum(img_neg_pixels))/len(img_prob)#np.sum(img_neg_pixels)\n",
    "        \n",
    "        #predict.csv\n",
    "       \n",
    "        img_temp_thresh = np.array(img_temp > threshold,dtype=np.float32)        \n",
    "        #img_temp=scipy.ndimage.morphology.binary_fill_holes(img_temp_thresh)\n",
    "        #img_temp = morphology.remove_small_objects(img_temp, 2000).astype(np.float)    \n",
    "        #img_temp_seed=cv2.erode(img_temp, kernel, iterations=1)\n",
    "        #img_temp=skimage.morphology.reconstruction(img_temp_seed,img_temp_thresh,selem=skimage.morphology.selem.disk(3))\n",
    "        #img_temp=(scipy.ndimage.morphology.binary_fill_holes(img_temp)).astype(np.float)\n",
    "        \n",
    "        #img_temp=(scipy.ndimage.morphology.binary_fill_holes(img_temp)).astype(np.float)        \n",
    "        pred_img_name=img_name#.split('.')[0]+'_pred.jpg'\n",
    "        lines.append([pred_img_name,prob_score])\n",
    "        pred_img_path=os.path.join(pred_dir,pred_img_name)\n",
    "        skimage.io.imsave(pred_img_path,img_as_uint(img_temp))\n",
    "        #print(\"time for {} shaped {} is {} s\".format((r,c),img_name,time.time()-str_time))\n",
    "        del img_temp,ar2\n",
    "        with open('predictions.csv', mode='w') as writeFile:\n",
    "            fields=['image_name','score']\n",
    "            writer = csv.writer(writeFile)\n",
    "            writer.writerow(fields)\n",
    "            writer.writerows(lines)\n",
    "    \n",
    "    print(\"DONE\")\n",
    "\n",
    "    \n",
    "#### PREDICT ###\n",
    "#pred_dir_name='/input'\n",
    "#img_list=os.listdir(pred_dir_name)\n",
    "\n",
    "#output_dir_name='/output'\n",
    "\n",
    "######\n",
    "MASK_PATH='/home/vahadaneabhi01/datalab/digest/Colonoscopy_tissue_segment_dataset/tissue-train-pos-v1_mask'\n",
    "IMAGE_PATH='/home/vahadaneabhi01/datalab/digest/Colonoscopy_tissue_segment_dataset/tissue-train-pos-v1_color_normalized'\n",
    "NEG_IMAGE_PATH='/datalab/digest/Colonoscopy_tissue_segment_dataset/tissue-train-neg_norm'\n",
    "\n",
    "#NEG_IMAGE_PATH='/datalab/digest/Colonoscopy_tissue_segment_dataset/tissue-train-neg'\n",
    "neg_img_list=os.listdir(NEG_IMAGE_PATH)\n",
    "\n",
    "all_img_list=os.listdir(IMAGE_PATH)\n",
    "INPUT_IMAGE_PATH_TEST='/home/vahadaneabhi01/datalab/digest/Colonoscopy_tissue_segment_dataset/input_cn_overlap_test'\n",
    "\n",
    "\n",
    "test_files=os.listdir(INPUT_IMAGE_PATH_TEST)\n",
    "test_img_list=['_'.join(x.split('_')[:-2])+'.jpg' for x in test_files]\n",
    "test_img_list=list(dict.fromkeys(test_img_list))\n",
    "\n",
    "# whole_img_pred(IMAGE_PATH,test_img_list,'whole_pred_junk_{}'.format(datetime.datetime.now().strftime(\"%Y_%m_%d\")),\\\n",
    "#                MASK_PATH,cal_performace=True)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entire_image_2019_10_14 directory already exists in /datalab/digest/Colonoscopy_tissue_segment_dataset\n",
      "Original image shape is (9314, 12688)\n",
      "Padded image dimensions are (9728, 25088, 3)\n",
      " Number of rows are 19 and columns are 49\n",
      "(9314, 12688)\n",
      "(9314, 12688)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1014 18:28:38.333432 140518152927040 util.py:64] Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for (9314, 12688) shaped D201707788_2019-05-14 14_05_34-lv1-2777-15975-12688-9314.jpg is 124.58131122589111 s\n",
      "Score : 0.6624420331597789\n",
      "Recall: 0.8274544282336693\n",
      "Original image shape is (28621, 19192)\n",
      "Padded image dimensions are (28672, 37888, 3)\n",
      " Number of rows are 56 and columns are 74\n",
      "(28621, 19192)\n",
      "(28621, 19192)\n"
     ]
    }
   ],
   "source": [
    "from skimage import img_as_uint\n",
    "def whole_img_pred(IMAGE_PATH,img_list,pred_dir_name,MASK_PATH=None,cal_performace=True):\n",
    "    \n",
    "    pred_dir=os.path.join(os.getcwd(),pred_dir_name)\n",
    "    \n",
    "    if not os.path.exists(pred_dir):\n",
    "        os.mkdir(pred_dir)\n",
    "        print(\"Made {} directory\".format(pred_dir.split('/')[-1]))\n",
    "    else:\n",
    "        print(\"{} directory already exists in {}\".format(pred_dir.split('/')[-1],'/'.join(pred_dir.split('/')[:-1])))\n",
    "        \n",
    "        \n",
    "\n",
    "    avg_recall=0\n",
    "    avg_dice=0\n",
    "    test_num=len(img_list)\n",
    "    left_scale=np.ones((512,512))\n",
    "    left_scale[:256,:]=0.5\n",
    "    right_scale=np.ones((512,512))\n",
    "    right_scale[256:,:]=0.5\n",
    "    kernel=skimage.morphology.disk(2, dtype=np.uint8)\n",
    "    for img_name in img_list:\n",
    "        str_time=time.time()\n",
    "\n",
    "        img=imread(os.path.join(IMAGE_PATH,img_name))\n",
    "        r,c,_=img.shape#4663,3881\n",
    "        print(\"Original image shape is {}\".format((r,c)))\n",
    "      \n",
    "        new_r_count=(math.ceil((r-512)/512)+1)#10\n",
    "        new_c_count=(math.ceil((c-512)/256)+1)#8\n",
    "\n",
    "\n",
    "        pad_r1=((new_r_count-1)*512-r+512)//2 #228\n",
    "        pad_r2=((new_r_count-1)*512-r+512)-pad_r1 #229\n",
    "        pad_c1=((new_c_count-1)*512-c+512)//2 #107\n",
    "        pad_c2=((new_c_count-1)*512-c+512)-pad_c1#108\n",
    "\n",
    "        arr_in=np.pad(img, [(pad_r1,pad_r2),(pad_c1,pad_c2),(0,0)], 'constant', constant_values=0)/255\n",
    "        print(\"Padded image dimensions are {}\".format(arr_in.shape))\n",
    "        window_shape=(512,512,3)\n",
    "        arr_out=skimage.util.view_as_windows(arr_in, window_shape, step=512)\n",
    "        x,y=arr_out.shape[:2]\n",
    "        print(\" Number of rows are {} and columns are {}\".format(x,y))\n",
    "        ar2=arr_out.reshape((-1,512,512,3))\n",
    "        del arr_out,arr_in,img\n",
    "        y_pred=loaded_model.predict(ar2)\n",
    "        \n",
    "    \n",
    "        img_temp=[]\n",
    "        for i in range(x):\n",
    "            img_temp.append(np.concatenate(y_pred[i*y:(i+1)*y],axis=1))\n",
    "        img_temp=np.array(img_temp,dtype=np.float_)\n",
    "\n",
    "        img_temp=np.concatenate(img_temp,axis=0)\n",
    "           \n",
    "#         y_pred=np.squeeze(loaded_model.predict(ar2))\n",
    "        \n",
    "        \n",
    "    \n",
    "#         img_temp=np.zeros((arr_in.shape[:2]))\n",
    "#         for i in range(x):\n",
    "#             print(i+1,\" ROW\")\n",
    "#             y_pred_temp=np.zeros((512,arr_in.shape[1]))\n",
    "#             for j in range(y):\n",
    "#                 y_pred_temp[:,j*256:j*256+512]+=y_pred[j]\n",
    "                \n",
    "#             img_temp[i*256:i*256+512,:]+=y_pred_temp\n",
    "#             #img_temp.append(np.concatenate(y_pred_temp,axis=1))\n",
    "#         img_temp=np.array(img_temp,dtype=np.float_)\n",
    "\n",
    "#         img_temp=np.concatenate(img_temp,axis=0)\n",
    "        img_temp=img_temp[pad_r1:img_temp.shape[0]-pad_r2,pad_c1:img_temp.shape[1]-pad_c2,:]#*255\n",
    "        thresh = 0.8#threshold_otsu(img_temp)\n",
    "        img_thresh_initial = np.squeeze(np.array(img_temp > 0.6,dtype=np.float32))\n",
    "        print(img_thresh_initial.shape)\n",
    "        img_thresh=scipy.ndimage.morphology.binary_fill_holes(img_thresh_initial)\n",
    "        img_thresh = morphology.remove_small_objects(img_thresh, 2000).astype(np.float) \n",
    "        \n",
    "        img_temp_seed=cv2.erode(np.float32(img_thresh), kernel, iterations=5)\n",
    "        print(img_temp_seed.shape)\n",
    "        img_thresh=skimage.morphology.reconstruction(img_temp_seed, img_thresh, method='dilation', selem=None, offset=None)\n",
    "        pred_img_name=img_name.split('.')[0]+'_pred.jpg'\n",
    "        pred_img_path=os.path.join(pred_dir,pred_img_name)\n",
    "        skimage.io.imsave(pred_img_path,img_thresh)\n",
    "        print(\"time for {} shaped {} is {} s\".format((r,c),img_name,time.time()-str_time))\n",
    "        if cal_performace:\n",
    "            mask_path=os.path.join(MASK_PATH,img_name.split('.')[0]+'_mask.jpg')\n",
    "            mask=imread(mask_path,as_gray=True)//255\n",
    "            dice_score=dice(mask, img_thresh)\n",
    "            recall_score=recall(mask,img_thresh)\n",
    "            avg_dice+=dice_score\n",
    "            avg_recall+=recall_score\n",
    "            print(\"Score : {}\\nRecall: {}\".format(dice_score,recall_score))\n",
    "        del img_temp,ar2\n",
    "        if cal_performace:\n",
    "            del mask\n",
    "    if cal_performace:\n",
    "        print(\"Average Dice : {}\".format(avg_dice/test_num))\n",
    "        print(\"Average Recall : {}\".format(avg_recall/test_num))\n",
    "    \n",
    "    print(\"DONE\")\n",
    "        \n",
    "MASK_PATH='/home/vahadaneabhi01/datalab/digest/Colonoscopy_tissue_segment_dataset/tissue-train-pos-v1_mask'\n",
    "IMAGE_PATH='/home/vahadaneabhi01/datalab/digest/Colonoscopy_tissue_segment_dataset/tissue-train-pos-v1_color_normalized'\n",
    "NEG_IMAGE_PATH='/datalab/digest/Colonoscopy_tissue_segment_dataset/tissue-train-neg_norm'\n",
    "\n",
    "#NEG_IMAGE_PATH='/datalab/digest/Colonoscopy_tissue_segment_dataset/tissue-train-neg'\n",
    "neg_img_list=os.listdir(NEG_IMAGE_PATH)\n",
    "\n",
    "all_img_list=os.listdir(IMAGE_PATH)\n",
    "INPUT_IMAGE_PATH_TEST='/home/vahadaneabhi01/datalab/digest/Colonoscopy_tissue_segment_dataset/input_cn_overlap_test'\n",
    "\n",
    "\n",
    "test_files=os.listdir(INPUT_IMAGE_PATH_TEST)\n",
    "test_img_list=['_'.join(x.split('_')[:-2])+'.jpg' for x in test_files]\n",
    "test_img_list=list(dict.fromkeys(test_img_list))\n",
    "\n",
    "whole_img_pred(IMAGE_PATH,test_img_list,'entire_image_{}'.format(datetime.datetime.now().strftime(\"%Y_%m_%d\")),\\\n",
    "               MASK_PATH,cal_performace=True)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kernel=skimage.morphology.disk(2, dtype=np.uint8)\n",
    "print(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "file_paths=[os.path.join('whole_pred_junk_2019_09_27',x) for x in os.listdir('whole_pred_junk_2019_09_27')]\n",
    "with ZipFile('pred.zip','w') as zip: \n",
    "        # writing each file one by one \n",
    "        for file in file_paths: \n",
    "            zip.write(file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/home/vahadaneabhi01/datalab/digest/Colonoscopy_tissue_segment_dataset/whole_pred_junk_2019_09_26/D20170502603_2019-05-14 11_39_00-lv1-19545-91-19192-28621.jpg'\n",
    "img_temp=imread(path)\n",
    "\n",
    "#kernel2 = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(15,15))\n",
    "img_temp2=cv2.erode(img_temp, skimage.morphology.selem.disk(11), iterations=1)\n",
    "#img_temp=cv2.dilate(img_temp, kernel2, iterations=3)\n",
    "#img_temp=cv2.erode(img_temp, kernel, iterations=2)\n",
    "#img_temp=cv2.dilate(img_temp, kernel2, iterations=3)\n",
    "plt.imshow(img_temp2)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_tempx=cv2.erode(img_temp2, kernel, iterations=3)\n",
    "img_temp3=skimage.morphology.reconstruction(img_temp2,img_temp,selem=skimage.morphology.selem.disk(3))\n",
    "#img_temp=cv2.dilate(img_temp, kernel2, iterations=3)\n",
    "#img_temp=cv2.erode(img_temp, kernel, iterations=2)\n",
    "#img_temp=cv2.dilate(img_temp, kernel2, iterations=3)\n",
    "plt.imshow(img_temp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_temp2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_temp4=(scipy.ndimage.morphology.binary_fill_holes(img_temp3)).astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_temp4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skimage.io.imsave('asd2.jpg',img_temp4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(skimage.morphology.selem.disk(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kernel.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(20,20))\n",
    "print(type(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_img_pred(NEG_IMAGE_PATH,neg_img_list,'whole_pred_neg_{}'.format(datetime.datetime.now().strftime(\"%Y_%m_%d\")),\\\n",
    "               MASK_PATH,cal_performace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img='/datalab/digest/Colonoscopy_tissue_segment_dataset/2019-10962-1-1-1_2019-05-28 15_22_19-lv1-35695-22595-1269-1099.jpg'\n",
    "img2=imread(img)\n",
    "print(img2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=imread('/datalab/digest/Colonoscopy_tissue_segment_dataset/whole_pred_test_2019_09_25/D20170502603_2019-05-14 11_39_00-lv1-19545-91-19192-28621_pred.jpg')\n",
    "kernel2 = np.ones((int(img.shape[0]*0.01),int(img.shape[1]*0.1)), np.uint8)\n",
    "kernel=np.ones((25,25), np.uint8)\n",
    "iterations=5\n",
    "\n",
    "img=scipy.ndimage.morphology.binary_fill_holes(img)\n",
    "\n",
    "img=cv2.dilate(img, kernel, iterations=iterations) \n",
    "img=cv2.erode(img, kernel, iterations=1)\n",
    "\n",
    "#import scipy\n",
    "#img2=scipy.ndimage.morphology.binary_fill_holes(img)\n",
    "plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_list=list(dict.fromkeys(test_img_list))\n",
    "print(len(test_img_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img3 = morphology.remove_small_objects(img2, 150*150)\n",
    "plt.imshow(img3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skimage.io.imsave('sample.jpg',img_as_uint(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=np.zeros((5,5,3))\n",
    "b[2:4]=1\n",
    "a=b[b!=0]\n",
    "print(np.sum(a)/len(a),b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
